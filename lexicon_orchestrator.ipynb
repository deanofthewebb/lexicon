{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon - Orchestrator\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "For this project, I will build a simple custom ochestrator that processes data objects from the \"Lexicon\" class.\n",
    "    - These objects are custom datasets that are modeled after the Ted Talk speakers. \n",
    "    - Each Lexicon has a corpus and some helper methods aimed at training and prediction\n",
    "    - Lexicon class will also have a preprocessing and caching function.\n",
    "    - Each object will have two methods of prediction, n-gram language model and a recurrent neural network model\n",
    "    - Each object has a custom reporting function that reports the results of training\n",
    "    - Each object will be able to learn from any text data provided, and return a transcript with confidence values from input posed in speech utterances. \n",
    "        - I will use Google's cloud-based services to preprocess the input audio data and transcribe into an initial guess. Then I will train a model to improve on Google cloud speech API's response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use to reload modules\n",
    "from importlib import reload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import tarfile\n",
    "\n",
    "librispeech_dataset_folder_path = 'LibriSpeech'\n",
    "tar_gz_path = 'dev-clean.tar.gz'\n",
    "\n",
    "books_path = 'original-books.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(books_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Librispeech Book Texts') as pbar:\n",
    "        urlretrieve(\n",
    "            'http://www.openslr.org/resources/12/original-books.tar.gz',\n",
    "            books_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(librispeech_dataset_folder_path+'/books'):\n",
    "    with tarfile.open(books_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        \n",
    "        \n",
    "        \n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Librispeech dev-clean.tar.gz') as pbar:\n",
    "        urlretrieve(\n",
    "            'http://www.openslr.org/resources/12/dev-clean.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(librispeech_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 41 text files in the directories /src/lexicon/LibriSpeech/books/utf-8/**/*.txt*\n",
      "97 segmented text files in the /src/lexicon/LibriSpeech/dev-clean/**/*.txt* directory and \n",
      "774 stm files in directory: /src/lexicon/TEDLIUM_release1/train/**/*.stm:\n"
     ]
    }
   ],
   "source": [
    "# Prepare a plain text corpus from which we train a languague model\n",
    "import glob\n",
    "import os\n",
    "import utils\n",
    "\n",
    "# Gather all text files from directory\n",
    "LIBRISPEECH_DIRECTORY = os.path.join(os.getcwd(),'LibriSpeech/')\n",
    "TEDLIUM_DIRECTORY = os.path.join(os.getcwd(),'TEDLIUM_release1/')\n",
    "\n",
    "# TRAINING_DIRECTORY = os.path.abspath(os.path.join(os.sep,'Volumes',\"My\\ Passport\\ for\\ Mac\",'lexicon','LibriSpeech'))\n",
    "dev_librispeech_path = \"{}{}{}{}\".format(LIBRISPEECH_DIRECTORY, 'dev-clean/', '**/', '*.txt*')\n",
    "train_librispeech_path = \"{}{}{}{}{}\".format(LIBRISPEECH_DIRECTORY, 'books/', 'utf-8/', '**/', '*.txt*')\n",
    "TED_path = \"{}{}{}{}\".format(TEDLIUM_DIRECTORY,'train/','**/', '*.stm')\n",
    "\n",
    "text_paths = sorted(glob.glob(train_librispeech_path, recursive=True))\n",
    "segmented_text_paths = sorted(glob.glob(dev_librispeech_path, recursive=True))\n",
    "stm_paths = sorted(glob.glob(TED_path, recursive=True))\n",
    "\n",
    "print('Found:',len(text_paths),\"text files in the directories {0}\\n{1} segmented text files in the {2} directory and \\n{3} stm files in directory: {4}:\".format(train_librispeech_path, \n",
    "        len(segmented_text_paths), dev_librispeech_path, len(stm_paths),TED_path ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Text Corpuses for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "import codecs\n",
    "import string\n",
    "from lexicon import Lexicon\n",
    "from speech import Speech\n",
    "      \n",
    "librispeech_corpus = u\"\"\n",
    "stm_segments = []\n",
    "lexicons = {} # {speaker_id: lexicon_object}\n",
    "speeches = {} # {speech_id: speech_object}\n",
    "segmented_librispeeches = {}\n",
    "\n",
    "for book_filename in text_paths[:10]: # 1 Book\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        lines = book_file.read()\n",
    "        librispeech_corpus += lines\n",
    "for stm_filename in stm_paths: # Process STM files (Tedlium)\n",
    "        stm_segments.append(utils.parse_stm_file(stm_filename))\n",
    "        \n",
    "\n",
    "# Train on 3 speakers\n",
    "for segments in stm_segments[15:17]: \n",
    "    for segment in segments:\n",
    "        segment_key = \"{0}_{1}_{2}\".format(segment.speaker_id.strip(), str(segment.start_time).replace('.','_'),\n",
    "                                          str(segment.stop_time).replace('.','_'))\n",
    "        if segment.speaker_id not in speeches.keys():\n",
    "            source_file = os.path.join(os.getcwd(), 'TEDLIUM_release1',\n",
    "                                       'train','sph', '{}.sph'.format(segment.filename))\n",
    "            speech = Speech(speaker_id=segment.speaker_id,\n",
    "                                           speech_id = segment_key,\n",
    "                                           source_file=source_file,\n",
    "                                           ground_truth = ' '.join(segment.transcript.split()[:-1]),\n",
    "                                           start = segment.start_time,\n",
    "                                           stop = segment.stop_time,\n",
    "                                           audio_type = 'LINEAR16')\n",
    "        else:\n",
    "            speech = speeches[segment.speaker_id.strip()]\n",
    "            print('Already found speech in list at location: ', speech)\n",
    "        \n",
    "        speeches[segment_key] = speech\n",
    "\n",
    "        if segment.speaker_id not in lexicons.keys():\n",
    "            lexicon = Lexicon(base_corpus=librispeech_corpus, name=segment.speaker_id)\n",
    "            lexicons[segment.speaker_id.strip()] = lexicon\n",
    "        else:\n",
    "            lexicon = lexicons[segment.speaker_id.strip()]\n",
    "        \n",
    "        # Add Speech to Lexicon\n",
    "        if speech not in lexicon.speeches:\n",
    "            lexicon.add_speech(speech)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GCS Transcripts using GCS Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "InvalidArgumentError(RPC failed, caused by <_Rendezvous of RPC that terminated with (StatusCode.INVALID_ARGUMENT, Request payload size exceeds the limit: 10485760 bytes.)>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_Rendezvous\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.5/site-packages/google/gax/api_callable.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0ma_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;31m# pylint: disable=catching-non-exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.5/site-packages/google/gax/retry.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mupdated_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0ma_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mupdated_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.5/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials)\u001b[0m\n\u001b[1;32m    491\u001b[0m                                                credentials)\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.5/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_Rendezvous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_Rendezvous\u001b[0m: <_Rendezvous of RPC that terminated with (StatusCode.INVALID_ARGUMENT, Request payload size exceeds the limit: 10485760 bytes.)>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cb0994fc2177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlexicon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mspeech\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeeches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe_speech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mspeech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_gcs_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mspeech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/lexicon/gcs_api_wrapper.py\u001b[0m in \u001b[0;36mtranscribe_speech\u001b[0;34m(self, audio_filepath)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# Detects speech and words in the audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0moperation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong_running_recognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.5/site-packages/google/cloud/gapic/speech/v1/speech_client.py\u001b[0m in \u001b[0;36mlong_running_recognize\u001b[0;34m(self, config, audio, options)\u001b[0m\n\u001b[1;32m    248\u001b[0m         return google.gax._OperationFuture(\n\u001b[1;32m    249\u001b[0m             self._long_running_recognize(request,\n\u001b[0;32m--> 250\u001b[0;31m                                          options), self.operations_client,\n\u001b[0m\u001b[1;32m    251\u001b[0m             \u001b[0mcloud_speech_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongRunningRecognizeResponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             cloud_speech_pb2.LongRunningRecognizeMetadata, options)\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.5/site-packages/google/gax/api_callable.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(request, options)\u001b[0m\n\u001b[1;32m    450\u001b[0m                 func, this_settings.timeout, **this_settings.kwargs)\n\u001b[1;32m    451\u001b[0m         \u001b[0mapi_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_catch_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPI_ERRORS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapi_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_descriptor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.5/site-packages/google/gax/api_callable.py\u001b[0m in \u001b[0;36mbase_caller\u001b[0;34m(api_call, _, *args)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbase_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;34m\"\"\"Simply call api_call and ignore settings.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapi_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.5/site-packages/google/gax/api_callable.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_catch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             utils.raise_with_traceback(\n\u001b[0;32m--> 380\u001b[0;31m                 gax.errors.create_error('RPC failed', cause=exception))\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.5/site-packages/future/utils/__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(exc, traceback)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.5/site-packages/google/gax/api_callable.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;34m\"\"\"Wraps specified exceptions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0ma_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;31m# pylint: disable=catching-non-exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_catch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.5/site-packages/google/gax/retry.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;34m\"\"\"Updates args with the timeout.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mupdated_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0ma_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mupdated_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.5/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials)\u001b[0m\n\u001b[1;32m    490\u001b[0m         state, call, deadline = self._blocking(request, timeout, metadata,\n\u001b[1;32m    491\u001b[0m                                                credentials)\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwith_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.5/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_Rendezvous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: InvalidArgumentError(RPC failed, caused by <_Rendezvous of RPC that terminated with (StatusCode.INVALID_ARGUMENT, Request payload size exceeds the limit: 10485760 bytes.)>)"
     ]
    }
   ],
   "source": [
    "from gcs_api_wrapper import GCSWrapper\n",
    "gcs = GCSWrapper()\n",
    "for speaker_id, lexicon in lexicons.items():\n",
    "    lexicon.preprocess_and_save()\n",
    "    for speech in lexicon.speeches:\n",
    "        result = gcs.transcribe_speech(speech.audio_file)\n",
    "        speech.populate_gcs_results(result)\n",
    "        speech.preprocess_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 58050\n",
      "Number of sentences: 27600\n",
      "Average number of words in a sentence: 23.997463768115942\n",
      "\n",
      "Transcript sentences 0 to 10:\n",
      "\n",
      "\n",
      "\"I shall never be better,\" said Jane Merrick, sternly\n",
      " \"The end is not\n",
      "far off now\n",
      "\"\n",
      "\n",
      "\"Oh, I'm sorry to hear you say that!\" said Patsy; \"but I hope it is\n",
      "not true\n",
      " Why, here are we four newly found relations all beginning to\n",
      "get acquainted, and to love one another, and we can't have our little\n",
      "party broken up, auntie dear\n",
      "\"\n",
      "\n",
      "\"Five of us--five relations,\" cried Uncle John, coming around the\n",
      "corner of the hedge\n",
      " \"Don't I count, Patsy, you rogue? Why you're\n",
      "looking as bright and as bonny as can be\n",
      " I wouldn't be surprised if\n",
      "you could toddle\n",
      "\"\n",
      "\n",
      "\"Not yet,\" she answered, cheerfully\n",
      " \"But I'm doing finely, Uncle\n",
      "John, and it won't be long before I can get about as well as ever\n",
      "\"\n",
      "\n",
      "\"And to think,\" said Aunt Jane, bitterly, \"that all this trouble was\n",
      "caused by that miserable boy! If I knew where to send him he'd not\n",
      "stay at Elmhurst a day longer\n",
      "\n",
      "Ground Truth sentences 0 to 10:\n",
      "\n",
      "\n",
      "\"I shall never be better,\" said Jane Merrick, sternly\n",
      " \"The end is not\n",
      "far off now\n",
      "\"\n",
      "\n",
      "\"Oh, I'm sorry to hear you say that!\" said Patsy; \"but I hope it is\n",
      "not true\n",
      " Why, here are we four newly found relations all beginning to\n",
      "get acquainted, and to love one another, and we can't have our little\n",
      "party broken up, auntie dear\n",
      "\"\n",
      "\n",
      "\"Five of us--five relations,\" cried Uncle John, coming around the\n",
      "corner of the hedge\n",
      " \"Don't I count, Patsy, you rogue? Why you're\n",
      "looking as bright and as bonny as can be\n",
      " I wouldn't be surprised if\n",
      "you could toddle\n",
      "\"\n",
      "\n",
      "\"Not yet,\" she answered, cheerfully\n",
      " \"But I'm doing finely, Uncle\n",
      "John, and it won't be long before I can get about as well as ever\n",
      "\"\n",
      "\n",
      "\"And to think,\" said Aunt Jane, bitterly, \"that all this trouble was\n",
      "caused by that miserable boy! If I knew where to send him he'd not\n",
      "stay at Elmhurst a day longer\n",
      "\n",
      "Dataset Stats\n",
      "Roughly the number of unique words: 57965\n",
      "Number of sentences: 27540\n",
      "Average number of words in a sentence: 24.005228758169935\n",
      "\n",
      "Transcript sentences 0 to 10:\n",
      "\n",
      "\n",
      "\"I shall never be better,\" said Jane Merrick, sternly\n",
      " \"The end is not\n",
      "far off now\n",
      "\"\n",
      "\n",
      "\"Oh, I'm sorry to hear you say that!\" said Patsy; \"but I hope it is\n",
      "not true\n",
      " Why, here are we four newly found relations all beginning to\n",
      "get acquainted, and to love one another, and we can't have our little\n",
      "party broken up, auntie dear\n",
      "\"\n",
      "\n",
      "\"Five of us--five relations,\" cried Uncle John, coming around the\n",
      "corner of the hedge\n",
      " \"Don't I count, Patsy, you rogue? Why you're\n",
      "looking as bright and as bonny as can be\n",
      " I wouldn't be surprised if\n",
      "you could toddle\n",
      "\"\n",
      "\n",
      "\"Not yet,\" she answered, cheerfully\n",
      " \"But I'm doing finely, Uncle\n",
      "John, and it won't be long before I can get about as well as ever\n",
      "\"\n",
      "\n",
      "\"And to think,\" said Aunt Jane, bitterly, \"that all this trouble was\n",
      "caused by that miserable boy! If I knew where to send him he'd not\n",
      "stay at Elmhurst a day longer\n",
      "\n",
      "Ground Truth sentences 0 to 10:\n",
      "\n",
      "\n",
      "\"I shall never be better,\" said Jane Merrick, sternly\n",
      " \"The end is not\n",
      "far off now\n",
      "\"\n",
      "\n",
      "\"Oh, I'm sorry to hear you say that!\" said Patsy; \"but I hope it is\n",
      "not true\n",
      " Why, here are we four newly found relations all beginning to\n",
      "get acquainted, and to love one another, and we can't have our little\n",
      "party broken up, auntie dear\n",
      "\"\n",
      "\n",
      "\"Five of us--five relations,\" cried Uncle John, coming around the\n",
      "corner of the hedge\n",
      " \"Don't I count, Patsy, you rogue? Why you're\n",
      "looking as bright and as bonny as can be\n",
      " I wouldn't be surprised if\n",
      "you could toddle\n",
      "\"\n",
      "\n",
      "\"Not yet,\" she answered, cheerfully\n",
      " \"But I'm doing finely, Uncle\n",
      "John, and it won't be long before I can get about as well as ever\n",
      "\"\n",
      "\n",
      "\"And to think,\" said Aunt Jane, bitterly, \"that all this trouble was\n",
      "caused by that miserable boy! If I knew where to send him he'd not\n",
      "stay at Elmhurst a day longer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "view_sentence_range = (0, 10)\n",
    "\n",
    "for speaker_id, lexicon in lexicons.items():\n",
    "    print('Dataset Stats')\n",
    "    print('Roughly the number of unique words: {}'.format(lexicon.vocab_size))\n",
    "    \n",
    "    word_counts = [len(sentence.split()) for sentence in lexicon.corpus_sentences]\n",
    "    print('Number of sentences: {}'.format(len(lexicon.corpus_sentences)))\n",
    "    print('Average number of words in a sentence: {}'.format(np.average(word_counts)))\n",
    "\n",
    "    print()\n",
    "    print('Transcript sentences {} to {}:'.format(*view_sentence_range))\n",
    "    print('\\n'.join(lexicon.training_set[0][view_sentence_range[0]:view_sentence_range[1]]))\n",
    "    print()\n",
    "    print('Ground Truth sentences {} to {}:'.format(*view_sentence_range))\n",
    "    print('\\n'.join(lexicon.training_set[1][view_sentence_range[0]:view_sentence_range[1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess Dataset - Tokenize Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import codecs\n",
    "import string\n",
    "\n",
    "# reading the file in unicode format using codecs library    \n",
    "stoplist = set(stopwords.words('english'))\n",
    "# Strip punctuation\n",
    "translate_table = dict((ord(char), None) for char in string.punctuation) \n",
    "        \n",
    "corpus_raw = u\"\"\n",
    "for book_filename in text_paths:\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        lines = book_file.read()\n",
    "        corpus_raw += lines.translate(translate_table) # remove punctuations \n",
    "\n",
    "               \n",
    "# Tokenize\n",
    "tokenized_words = nltk.tokenize.word_tokenize(corpus_raw)\n",
    "\n",
    "## Clean the tokens ##\n",
    "# Remove stop words\n",
    "tokenized_words = [word for word in tokenized_words if word not in stoplist]\n",
    "\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "tokenized_words = [word for word in tokenized_words if len(word) > 1]\n",
    "\n",
    "# Remove numbers\n",
    "tokenized_words = [word for word in tokenized_words if not word.isnumeric()]\n",
    "\n",
    "# Lowercase all words (default_stopwords are lowercase too)\n",
    "tokenized_words = [word.lower() for word in tokenized_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess Dataset - Extract N-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.collocations import *\n",
    "from nltk.probability import FreqDist\n",
    "import nltk\n",
    "\n",
    "# extracting the bi-grams and sorting them according to their frequencies\n",
    "finder = BigramCollocationFinder.from_words(tokenized_words)\n",
    "# finder.apply_freq_filter(3)\n",
    "\n",
    "bigram_model = nltk.bigrams(tokenized_words)\n",
    "bigram_model = sorted(bigram_model, key=lambda item: item[1], reverse=True)  \n",
    "# print(bigram_model)\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "np.save(\"lang_model.npy\",bigram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(bigram_model)\n",
    "\n",
    "# Output top 50 words\n",
    "print(\"Word|Freq:\")\n",
    "for word, frequency in fdist.most_common(50):\n",
    "    print(u'{}|{}'.format(word, frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfreq_2gram = nltk.ConditionalFreqDist(bigram_model)\n",
    "# print('Conditional Frequency Conditions:\\n', cfreq_2gram)\n",
    "print()\n",
    "\n",
    "# First access the FreqDist associated with \"one\", then the keys in that FreqDist\n",
    "print(\"Listing the words that can follow after 'greater':\\n\", cfreq_2gram[\"greater\"].keys())\n",
    "print()\n",
    "\n",
    "# Determine Most common in conditional frequency\n",
    "print(\"Listing 20 most frequent words to come after 'greater':\\n\", cfreq_2gram[\"greater\"].most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each word in the evaluation list:\n",
    "# Select word and determine its frequency distribution\n",
    "# Grab probability of second word in the list\n",
    "# Continue this process until the sentence is scored\n",
    "\n",
    "# Add small epsilon value to avoid division by zero\n",
    "epsilon = 0.0000001\n",
    "\n",
    "# Loads the audio into memory\n",
    "for audio, ground_truth in audio_files.items():\n",
    "    with io.open(audio, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "        audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.FLAC,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code='en-US',\n",
    "        max_alternatives=10,\n",
    "        profanity_filter=False,\n",
    "        enable_word_time_offsets=True)\n",
    "\n",
    "    # Detects speech and words in the audio file\n",
    "    operation = client.long_running_recognize(config, audio)\n",
    "\n",
    "    print('Waiting for operation to complete...')\n",
    "    result = operation.result(timeout=90)\n",
    "\n",
    "    alternatives = result.results[0].alternatives\n",
    "\n",
    "\n",
    "    #print(\"API Results: \", alternatives)\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    rerank_results = {}\n",
    "    for alternative in alternatives:\n",
    "        sent = alternative.transcript\n",
    "\n",
    "        words = nltk.tokenize.word_tokenize(sent)\n",
    "        probs = np.ones_like(words, dtype=np.float32)*epsilon\n",
    "        # print(words,'\\n',probs)\n",
    "        for word in words:\n",
    "            if words.index(word) < len(words)-1: \n",
    "                freq = cfreq_2gram[word].freq(words[words.index(word)+1])\n",
    "                probs[words.index(word)] = freq\n",
    "            # print(probs)\n",
    "\n",
    "        lexicon_score = np.sum(probs)\n",
    "        # print(word_score)\n",
    "\n",
    "        # Re-rank alternatives using a weighted average of the two scores\n",
    "        api_weight = 0.90\n",
    "        confidence_score = alternative.confidence*api_weight + lexicon_score*(1-api_weight)\n",
    "        rerank_results[alternative.transcript] = confidence_score\n",
    "\n",
    "    print(\"RE-RANKED Results: \\n\", rerank_results)\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    import operator\n",
    "    index, value = max(enumerate(list(rerank_results.values())), key=operator.itemgetter(1))\n",
    "    # Select Corresponding Transcript:\n",
    "    script=''\n",
    "    for trnscript, confidence in rerank_results.items():\n",
    "        if confidence == value:\n",
    "            script = trnscript\n",
    "\n",
    "    # Evaluate the differences between the Original and the Reranked transcript:\n",
    "    print(\"ORIGINAL Transcript: \\n'{0}' \\nwith a confidence_score of: {1}\".format(alternative.transcript, alternative.confidence))\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print(\"RE-RANKED Transcript: \\n'{0}' \\nwith a confidence_score of: {1}\".format(script, value))\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print(\"GROUND TRUTH TRANSCRIPT: \\n{0}\".format(ground_truth))\n",
    "    print()\n",
    "    ranked_differences = list(set(nltk.tokenize.word_tokenize(alternative.transcript.lower())) -\n",
    "                              set(nltk.tokenize.word_tokenize(script.lower())))\n",
    "    if len(ranked_differences) == 0:  \n",
    "        print(\"No reranking was performed. The transcripts match!\")\n",
    "    else:\n",
    "        print(\"The original transcript was RE-RANKED. The transcripts do not match!\")\n",
    "        print(\"Differences between original and re-ranked: \", ranked_differences)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    # Evaluate Differences between the Original and Ground Truth:\n",
    "    gt_orig_diff = list(set(nltk.tokenize.word_tokenize(alternative.transcript.lower())) -\n",
    "                              set(nltk.tokenize.word_tokenize(ground_truth.lower())))\n",
    "    if len(gt_orig_diff) == 0:  \n",
    "        print(\"The ORIGINAL transcript matches ground truth!\")\n",
    "    else:\n",
    "        print(\"The original transcript DOES NOT MATCH ground truth.\")\n",
    "        print(\"Differences between original and ground truth: \", gt_orig_diff)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    gt_rr_diff = list(set(nltk.tokenize.word_tokenize(script.lower())) -\n",
    "                              set(nltk.tokenize.word_tokenize(ground_truth.lower())))\n",
    "    if len(gt_rr_diff) == 0:  \n",
    "        print(\"The RE-RANKED transcript matches ground truth!\")\n",
    "    else:\n",
    "        print(\"The RE_RANKED transcript DOES NOT MATCH ground truth.\")\n",
    "        print(\"Differences between Reranked and ground truth: \", gt_rr_diff)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    # Compute the Levenshtein Distance (a.k.a. Edit Distance)\n",
    "#     import nltk.metrics.distance as lev_dist\n",
    "    \n",
    "    # Google API Edit Distance\n",
    "    goog_edit_distance = nltk.edit_distance(alternative.transcript.lower(), ground_truth.lower())\n",
    "    \n",
    "    # Re-Ranked Edit Distance\n",
    "    rr_edit_distance = nltk.edit_distance(script.lower(), ground_truth.lower())\n",
    "\n",
    "    \n",
    "    print(\"ORIGINAL Edit Distance: \\n{0}\".format(goog_edit_distance))\n",
    "    print(\"RE-RANKED Edit Distance: \\n{0}\".format(rr_edit_distance))\n",
    "    print()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all samples, load into dictionary\n",
    "# Prepare a plain text corpus from which we train a languague model\n",
    "import glob\n",
    "import operator\n",
    "\n",
    "# Gather all text files from directory\n",
    "WORKING_DIRECTORY = os.path.join(os.getcwd(),'LibriSpeech/')\n",
    "\n",
    "# TRAINING_DIRECTORY = os.path.abspath(os.path.join(os.sep,'Volumes',\"My\\ Passport\\ for\\ Mac\",'lexicon','LibriSpeech'))\n",
    "dev_path = \"{}{}{}{}\".format(WORKING_DIRECTORY, 'dev-clean/', '**/', '*.txt')\n",
    "train_path = \"{}{}{}{}{}\".format(WORKING_DIRECTORY, 'books/', 'utf-8/', '**/', '*.txt*')\n",
    "\n",
    "text_paths = sorted(glob.glob(dev_path, recursive=True))\n",
    "print('Found',len(text_paths),'text files in the directory:', dev_path)\n",
    "\n",
    "transcripts = {}\n",
    "for document in text_paths:\n",
    "    with codecs.open(document, 'r', 'utf-8') as filep:\n",
    "        for i,line in enumerate(filep):\n",
    "            transcripts[line.split()[0]] = ' '.join(line.split()[1:])\n",
    "\n",
    "# Save Dictionary in Pickle File\n",
    "\n",
    "\n",
    "## Evaluate all samples found ##\n",
    "cloud_speech_api_accuracy = []\n",
    "custom_lang_model_accuracy = []\n",
    "epsilon = 0.000000001\n",
    "api_weight = 0.85\n",
    "steps = 0\n",
    "# Pull In Audio File\n",
    "for filename, gt_transcript in transcripts.items():\n",
    "    steps += 1\n",
    "    dirs = filename.split('-')\n",
    "    \n",
    "    audio_filepath = dev_file_name_0 = os.path.join(\n",
    "    os.getcwd(),\n",
    "    'LibriSpeech',\n",
    "    'dev-clean',\n",
    "    dirs[0],\n",
    "    dirs[1],\n",
    "    \"{0}.flac\".format(filename))\n",
    "    \n",
    "    \n",
    "\n",
    "    # Load the audio into memory\n",
    "    with io.open(audio_filepath, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "        audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.FLAC,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code='en-US',\n",
    "        max_alternatives=10,\n",
    "        profanity_filter=False,\n",
    "        enable_word_time_offsets=True)\n",
    "\n",
    "    # Detects speech and words in the audio file\n",
    "    operation = client.long_running_recognize(config, audio)\n",
    "    result = operation.result(timeout=90)\n",
    "    alternatives = result.results[0].alternatives\n",
    "\n",
    "\n",
    "    # Evaluate API Results for Re-Ranking:\n",
    "    rerank_results = {}\n",
    "    for alternative in alternatives:\n",
    "        sent = alternative.transcript\n",
    "        \n",
    "        # Strip punctuation\n",
    "        translate_table = dict((ord(char), None) for char in string.punctuation)        \n",
    "        sent = sent.translate(translate_table) # remove punctuations\n",
    "\n",
    "        words = nltk.tokenize.word_tokenize(sent)\n",
    "        probs = np.ones_like(words, dtype=np.float32)*epsilon\n",
    "\n",
    "        for word in words:\n",
    "            if words.index(word) < len(words)-1: \n",
    "                freq = cfreq_2gram[word].freq(words[words.index(word)+1])\n",
    "                probs[words.index(word)] = freq\n",
    "\n",
    "        lexicon_score = np.sum(probs)\n",
    "\n",
    "        # Re-rank alternatives using a weighted average of the two scores\n",
    "        confidence_score = alternative.confidence*api_weight + lexicon_score*(1-api_weight)\n",
    "        rerank_results[alternative.transcript] = confidence_score\n",
    "\n",
    "\n",
    "    \n",
    "    index, value = max(enumerate(list(rerank_results.values())), key=operator.itemgetter(1))\n",
    "    # Select Corresponding Transcript:\n",
    "    script=''\n",
    "    for trnscript, confidence in rerank_results.items():\n",
    "        if confidence == value:\n",
    "            script = trnscript\n",
    "                \n",
    "    # Compute the Accuracy, based on the Levenshtein Distance (a.k.a. Edit Distance)\n",
    "    gcs_ed = nltk.edit_distance(alternative.transcript.lower(), gt_transcript.lower())\n",
    "    gcs_upper_bound = max(len(alternative.transcript),len(gt_transcript))\n",
    "    gcs_accuracy = (1.0 - gcs_ed/gcs_upper_bound)\n",
    "    \n",
    "    clm_ed = nltk.edit_distance(script.lower(), gt_transcript.lower())\n",
    "    clm_upper_bound = max(len(script),len(gt_transcript))\n",
    "    clm_accuracy = (1.0 - clm_ed/clm_upper_bound)\n",
    "    \n",
    "    cloud_speech_api_accuracy.append(gcs_accuracy)\n",
    "    custom_lang_model_accuracy.append(clm_accuracy)\n",
    "\n",
    "    if steps % 100 == 0:\n",
    "        print(\"{0} Transcripts Processed.\".format(steps))\n",
    "        print('Average API Accuracy:', np.mean(cloud_speech_api_accuracy))\n",
    "        print('Average Custom Model Accuracy:', np.mean(custom_lang_model_accuracy))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch  100/2536 - Train Accuracy: 0.5909, Validation Accuracy: 0.6339, Loss: 7.2264\n",
      "Epoch   0 Batch  200/2536 - Train Accuracy: 0.7076, Validation Accuracy: 0.6339, Loss: 4.1828\n",
      "Epoch   0 Batch  300/2536 - Train Accuracy: 0.6942, Validation Accuracy: 0.6339, Loss: 3.0281\n",
      "Epoch   0 Batch  400/2536 - Train Accuracy: 0.6309, Validation Accuracy: 0.6339, Loss: 3.5545\n",
      "Epoch   0 Batch  500/2536 - Train Accuracy: 0.5312, Validation Accuracy: 0.6339, Loss: 4.1028\n",
      "Epoch   0 Batch  600/2536 - Train Accuracy: 0.5458, Validation Accuracy: 0.6339, Loss: 3.8562\n",
      "Epoch   0 Batch  700/2536 - Train Accuracy: 0.5481, Validation Accuracy: 0.6339, Loss: 3.7842\n",
      "Epoch   0 Batch  800/2536 - Train Accuracy: 0.5264, Validation Accuracy: 0.6339, Loss: 3.8614\n",
      "Epoch   0 Batch  900/2536 - Train Accuracy: 0.4085, Validation Accuracy: 0.6339, Loss: 4.4452\n",
      "Epoch   0 Batch 1000/2536 - Train Accuracy: 0.4813, Validation Accuracy: 0.6339, Loss: 3.8994\n",
      "Epoch   0 Batch 1100/2536 - Train Accuracy: 0.3304, Validation Accuracy: 0.6339, Loss: 5.1238\n",
      "Epoch   0 Batch 1200/2536 - Train Accuracy: 0.4512, Validation Accuracy: 0.6339, Loss: 4.2061\n",
      "Epoch   0 Batch 1300/2536 - Train Accuracy: 0.7139, Validation Accuracy: 0.6339, Loss: 2.7490\n",
      "Epoch   0 Batch 1400/2536 - Train Accuracy: 0.4708, Validation Accuracy: 0.6339, Loss: 4.0723\n",
      "Epoch   0 Batch 1500/2536 - Train Accuracy: 0.6202, Validation Accuracy: 0.6339, Loss: 3.1716\n",
      "Epoch   0 Batch 1600/2536 - Train Accuracy: 0.5365, Validation Accuracy: 0.6339, Loss: 3.7571\n",
      "Epoch   0 Batch 1700/2536 - Train Accuracy: 0.6051, Validation Accuracy: 0.6339, Loss: 3.0863\n",
      "Epoch   0 Batch 1800/2536 - Train Accuracy: 0.7301, Validation Accuracy: 0.6339, Loss: 2.2774\n",
      "Epoch   0 Batch 1900/2536 - Train Accuracy: 0.5286, Validation Accuracy: 0.6339, Loss: 3.4491\n",
      "Epoch   0 Batch 2000/2536 - Train Accuracy: 0.5529, Validation Accuracy: 0.6339, Loss: 3.5815\n",
      "Epoch   0 Batch 2100/2536 - Train Accuracy: 0.4297, Validation Accuracy: 0.6339, Loss: 4.5411\n",
      "Epoch   0 Batch 2200/2536 - Train Accuracy: 0.5583, Validation Accuracy: 0.6339, Loss: 3.3504\n",
      "Epoch   0 Batch 2300/2536 - Train Accuracy: 0.3582, Validation Accuracy: 0.6339, Loss: 5.2524\n",
      "Epoch   0 Batch 2400/2536 - Train Accuracy: 0.4639, Validation Accuracy: 0.6339, Loss: 4.2476\n",
      "Epoch   0 Batch 2500/2536 - Train Accuracy: 0.3894, Validation Accuracy: 0.6339, Loss: 4.8921\n",
      "Epoch   1 Batch  100/2536 - Train Accuracy: 0.6193, Validation Accuracy: 0.6339, Loss: 3.1221\n",
      "Epoch   1 Batch  200/2536 - Train Accuracy: 0.7210, Validation Accuracy: 0.6339, Loss: 2.3190\n",
      "Epoch   1 Batch  300/2536 - Train Accuracy: 0.7098, Validation Accuracy: 0.6339, Loss: 2.2163\n",
      "Epoch   1 Batch  400/2536 - Train Accuracy: 0.6406, Validation Accuracy: 0.6339, Loss: 2.8461\n",
      "Epoch   1 Batch  500/2536 - Train Accuracy: 0.5479, Validation Accuracy: 0.6339, Loss: 3.5333\n",
      "Epoch   1 Batch  600/2536 - Train Accuracy: 0.5625, Validation Accuracy: 0.6339, Loss: 3.4023\n",
      "Epoch   1 Batch  700/2536 - Train Accuracy: 0.5625, Validation Accuracy: 0.6339, Loss: 3.4124\n",
      "Epoch   1 Batch  800/2536 - Train Accuracy: 0.5577, Validation Accuracy: 0.6339, Loss: 3.5239\n",
      "Epoch   1 Batch  900/2536 - Train Accuracy: 0.4509, Validation Accuracy: 0.6339, Loss: 4.0458\n",
      "Epoch   1 Batch 1000/2536 - Train Accuracy: 0.4958, Validation Accuracy: 0.6339, Loss: 3.6225\n",
      "Epoch   1 Batch 1100/2536 - Train Accuracy: 0.3460, Validation Accuracy: 0.6339, Loss: 4.8449\n",
      "Epoch   1 Batch 1200/2536 - Train Accuracy: 0.4434, Validation Accuracy: 0.6339, Loss: 3.9044\n",
      "Epoch   1 Batch 1300/2536 - Train Accuracy: 0.7236, Validation Accuracy: 0.6339, Loss: 2.4641\n",
      "Epoch   1 Batch 1400/2536 - Train Accuracy: 0.4792, Validation Accuracy: 0.6339, Loss: 3.8692\n",
      "Epoch   1 Batch 1500/2536 - Train Accuracy: 0.6106, Validation Accuracy: 0.6339, Loss: 2.8666\n",
      "Epoch   1 Batch 1600/2536 - Train Accuracy: 0.5391, Validation Accuracy: 0.6339, Loss: 3.4744\n",
      "Epoch   1 Batch 1700/2536 - Train Accuracy: 0.6051, Validation Accuracy: 0.6339, Loss: 2.8452\n",
      "Epoch   1 Batch 1800/2536 - Train Accuracy: 0.7273, Validation Accuracy: 0.6339, Loss: 2.0574\n",
      "Epoch   1 Batch 1900/2536 - Train Accuracy: 0.5417, Validation Accuracy: 0.6339, Loss: 3.2644\n",
      "Epoch   1 Batch 2000/2536 - Train Accuracy: 0.5433, Validation Accuracy: 0.6339, Loss: 3.3645\n",
      "Epoch   1 Batch 2100/2536 - Train Accuracy: 0.4271, Validation Accuracy: 0.6339, Loss: 4.3419\n",
      "Epoch   1 Batch 2200/2536 - Train Accuracy: 0.5521, Validation Accuracy: 0.6339, Loss: 3.1774\n",
      "Epoch   1 Batch 2300/2536 - Train Accuracy: 0.3654, Validation Accuracy: 0.6339, Loss: 4.9791\n",
      "Epoch   1 Batch 2400/2536 - Train Accuracy: 0.4519, Validation Accuracy: 0.6339, Loss: 3.9678\n",
      "Epoch   1 Batch 2500/2536 - Train Accuracy: 0.3774, Validation Accuracy: 0.6339, Loss: 4.6516\n",
      "Epoch   2 Batch  100/2536 - Train Accuracy: 0.6165, Validation Accuracy: 0.6339, Loss: 2.9682\n",
      "Epoch   2 Batch  200/2536 - Train Accuracy: 0.7232, Validation Accuracy: 0.6339, Loss: 2.2223\n",
      "Epoch   2 Batch  300/2536 - Train Accuracy: 0.7076, Validation Accuracy: 0.6339, Loss: 2.1174\n",
      "Epoch   2 Batch  400/2536 - Train Accuracy: 0.6602, Validation Accuracy: 0.6339, Loss: 2.7390\n",
      "Epoch   2 Batch  500/2536 - Train Accuracy: 0.5542, Validation Accuracy: 0.6339, Loss: 3.4054\n",
      "Epoch   2 Batch  600/2536 - Train Accuracy: 0.5729, Validation Accuracy: 0.6339, Loss: 3.2650\n",
      "Epoch   2 Batch  700/2536 - Train Accuracy: 0.5721, Validation Accuracy: 0.6339, Loss: 3.2929\n",
      "Epoch   2 Batch  800/2536 - Train Accuracy: 0.5625, Validation Accuracy: 0.6339, Loss: 3.3933\n",
      "Epoch   2 Batch  900/2536 - Train Accuracy: 0.4598, Validation Accuracy: 0.6339, Loss: 3.8522\n",
      "Epoch   2 Batch 1000/2536 - Train Accuracy: 0.4938, Validation Accuracy: 0.6339, Loss: 3.4844\n",
      "Epoch   2 Batch 1100/2536 - Train Accuracy: 0.3371, Validation Accuracy: 0.6339, Loss: 4.6294\n",
      "Epoch   2 Batch 1200/2536 - Train Accuracy: 0.4492, Validation Accuracy: 0.6339, Loss: 3.6593\n",
      "Epoch   2 Batch 1300/2536 - Train Accuracy: 0.7163, Validation Accuracy: 0.6339, Loss: 2.3274\n",
      "Epoch   2 Batch 1400/2536 - Train Accuracy: 0.4917, Validation Accuracy: 0.6339, Loss: 3.6995\n",
      "Epoch   2 Batch 1500/2536 - Train Accuracy: 0.6346, Validation Accuracy: 0.6339, Loss: 2.6787\n",
      "Epoch   2 Batch 1600/2536 - Train Accuracy: 0.5365, Validation Accuracy: 0.6339, Loss: 3.2729\n",
      "Epoch   2 Batch 1700/2536 - Train Accuracy: 0.6193, Validation Accuracy: 0.6339, Loss: 2.6925\n",
      "Epoch   2 Batch 1800/2536 - Train Accuracy: 0.7330, Validation Accuracy: 0.6339, Loss: 1.9388\n",
      "Epoch   2 Batch 1900/2536 - Train Accuracy: 0.5391, Validation Accuracy: 0.6339, Loss: 3.0883\n",
      "Epoch   2 Batch 2000/2536 - Train Accuracy: 0.5385, Validation Accuracy: 0.6339, Loss: 3.1552\n",
      "Epoch   2 Batch 2100/2536 - Train Accuracy: 0.4323, Validation Accuracy: 0.6339, Loss: 4.0949\n",
      "Epoch   2 Batch 2200/2536 - Train Accuracy: 0.5563, Validation Accuracy: 0.6339, Loss: 2.9923\n",
      "Epoch   2 Batch 2300/2536 - Train Accuracy: 0.3582, Validation Accuracy: 0.6339, Loss: 4.7375\n",
      "Epoch   2 Batch 2400/2536 - Train Accuracy: 0.4495, Validation Accuracy: 0.6339, Loss: 3.6824\n",
      "Epoch   2 Batch 2500/2536 - Train Accuracy: 0.3726, Validation Accuracy: 0.6339, Loss: 4.4021\n",
      "Epoch   3 Batch  100/2536 - Train Accuracy: 0.6392, Validation Accuracy: 0.6339, Loss: 2.8021\n",
      "Epoch   3 Batch  200/2536 - Train Accuracy: 0.7254, Validation Accuracy: 0.6339, Loss: 2.1224\n",
      "Epoch   3 Batch  300/2536 - Train Accuracy: 0.7165, Validation Accuracy: 0.6339, Loss: 2.0214\n",
      "Epoch   3 Batch  400/2536 - Train Accuracy: 0.6582, Validation Accuracy: 0.6339, Loss: 2.6209\n",
      "Epoch   3 Batch  500/2536 - Train Accuracy: 0.5521, Validation Accuracy: 0.6339, Loss: 3.2469\n",
      "Epoch   3 Batch  600/2536 - Train Accuracy: 0.5750, Validation Accuracy: 0.6339, Loss: 3.1315\n",
      "Epoch   3 Batch  700/2536 - Train Accuracy: 0.5793, Validation Accuracy: 0.6339, Loss: 3.1707\n",
      "Epoch   3 Batch  800/2536 - Train Accuracy: 0.5553, Validation Accuracy: 0.6339, Loss: 3.2635\n",
      "Epoch   3 Batch  900/2536 - Train Accuracy: 0.4531, Validation Accuracy: 0.6339, Loss: 3.6418\n",
      "Epoch   3 Batch 1000/2536 - Train Accuracy: 0.5000, Validation Accuracy: 0.6339, Loss: 3.3108\n",
      "Epoch   3 Batch 1100/2536 - Train Accuracy: 0.3438, Validation Accuracy: 0.6339, Loss: 4.3829\n",
      "Epoch   3 Batch 1200/2536 - Train Accuracy: 0.4434, Validation Accuracy: 0.6339, Loss: 3.4651\n",
      "Epoch   3 Batch 1300/2536 - Train Accuracy: 0.7188, Validation Accuracy: 0.6339, Loss: 2.2043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3 Batch 1400/2536 - Train Accuracy: 0.4813, Validation Accuracy: 0.6339, Loss: 3.5463\n",
      "Epoch   3 Batch 1500/2536 - Train Accuracy: 0.6298, Validation Accuracy: 0.6339, Loss: 2.5367\n",
      "Epoch   3 Batch 1600/2536 - Train Accuracy: 0.5417, Validation Accuracy: 0.6339, Loss: 3.0918\n",
      "Epoch   3 Batch 1700/2536 - Train Accuracy: 0.6193, Validation Accuracy: 0.6339, Loss: 2.5742\n",
      "Epoch   3 Batch 1800/2536 - Train Accuracy: 0.7330, Validation Accuracy: 0.6339, Loss: 1.8495\n",
      "Epoch   3 Batch 1900/2536 - Train Accuracy: 0.5547, Validation Accuracy: 0.6339, Loss: 2.9556\n",
      "Epoch   3 Batch 2000/2536 - Train Accuracy: 0.5409, Validation Accuracy: 0.6339, Loss: 2.9973\n",
      "Epoch   3 Batch 2100/2536 - Train Accuracy: 0.4323, Validation Accuracy: 0.6339, Loss: 3.8470\n",
      "Epoch   3 Batch 2200/2536 - Train Accuracy: 0.5792, Validation Accuracy: 0.6339, Loss: 2.8359\n",
      "Epoch   3 Batch 2300/2536 - Train Accuracy: 0.3630, Validation Accuracy: 0.6339, Loss: 4.5660\n",
      "Epoch   3 Batch 2400/2536 - Train Accuracy: 0.4423, Validation Accuracy: 0.6339, Loss: 3.5216\n",
      "Epoch   3 Batch 2500/2536 - Train Accuracy: 0.3798, Validation Accuracy: 0.6339, Loss: 4.2388\n",
      "Epoch   4 Batch  100/2536 - Train Accuracy: 0.6335, Validation Accuracy: 0.6339, Loss: 2.6594\n",
      "Epoch   4 Batch  200/2536 - Train Accuracy: 0.7254, Validation Accuracy: 0.6339, Loss: 2.0399\n",
      "Epoch   4 Batch  300/2536 - Train Accuracy: 0.7165, Validation Accuracy: 0.6339, Loss: 1.9394\n",
      "Epoch   4 Batch  400/2536 - Train Accuracy: 0.6562, Validation Accuracy: 0.6339, Loss: 2.5335\n",
      "Epoch   4 Batch  500/2536 - Train Accuracy: 0.5542, Validation Accuracy: 0.6339, Loss: 3.1178\n",
      "Epoch   4 Batch  600/2536 - Train Accuracy: 0.5792, Validation Accuracy: 0.6339, Loss: 2.9982\n",
      "Epoch   4 Batch  700/2536 - Train Accuracy: 0.5793, Validation Accuracy: 0.6339, Loss: 3.0390\n",
      "Epoch   4 Batch  800/2536 - Train Accuracy: 0.5601, Validation Accuracy: 0.6339, Loss: 3.1291\n",
      "Epoch   4 Batch  900/2536 - Train Accuracy: 0.4509, Validation Accuracy: 0.6339, Loss: 3.4662\n",
      "Epoch   4 Batch 1000/2536 - Train Accuracy: 0.5208, Validation Accuracy: 0.6339, Loss: 3.1492\n",
      "Epoch   4 Batch 1100/2536 - Train Accuracy: 0.3326, Validation Accuracy: 0.6339, Loss: 4.2229\n",
      "Epoch   4 Batch 1200/2536 - Train Accuracy: 0.4707, Validation Accuracy: 0.6339, Loss: 3.3267\n",
      "Epoch   4 Batch 1300/2536 - Train Accuracy: 0.7236, Validation Accuracy: 0.6339, Loss: 2.0761\n",
      "Epoch   4 Batch 1400/2536 - Train Accuracy: 0.4875, Validation Accuracy: 0.6339, Loss: 3.4146\n",
      "Epoch   4 Batch 1500/2536 - Train Accuracy: 0.6370, Validation Accuracy: 0.6339, Loss: 2.4195\n",
      "Epoch   4 Batch 1600/2536 - Train Accuracy: 0.5599, Validation Accuracy: 0.6339, Loss: 2.9576\n",
      "Epoch   4 Batch 1700/2536 - Train Accuracy: 0.6364, Validation Accuracy: 0.6339, Loss: 2.4369\n",
      "Epoch   4 Batch 1800/2536 - Train Accuracy: 0.7472, Validation Accuracy: 0.6339, Loss: 1.7740\n",
      "Epoch   4 Batch 1900/2536 - Train Accuracy: 0.5833, Validation Accuracy: 0.6339, Loss: 2.8006\n",
      "Epoch   4 Batch 2000/2536 - Train Accuracy: 0.5529, Validation Accuracy: 0.6339, Loss: 2.8681\n",
      "Epoch   4 Batch 2100/2536 - Train Accuracy: 0.4349, Validation Accuracy: 0.6339, Loss: 3.5941\n",
      "Epoch   4 Batch 2200/2536 - Train Accuracy: 0.5813, Validation Accuracy: 0.6339, Loss: 2.6770\n",
      "Epoch   4 Batch 2300/2536 - Train Accuracy: 0.3630, Validation Accuracy: 0.6339, Loss: 4.3995\n",
      "Epoch   4 Batch 2400/2536 - Train Accuracy: 0.4543, Validation Accuracy: 0.6339, Loss: 3.3419\n",
      "Epoch   4 Batch 2500/2536 - Train Accuracy: 0.3918, Validation Accuracy: 0.6339, Loss: 4.0435\n",
      "Epoch   5 Batch  100/2536 - Train Accuracy: 0.6364, Validation Accuracy: 0.6339, Loss: 2.5401\n",
      "Epoch   5 Batch  200/2536 - Train Accuracy: 0.7366, Validation Accuracy: 0.6339, Loss: 1.9604\n",
      "Epoch   5 Batch  300/2536 - Train Accuracy: 0.7210, Validation Accuracy: 0.6339, Loss: 1.8573\n",
      "Epoch   5 Batch  400/2536 - Train Accuracy: 0.6582, Validation Accuracy: 0.6339, Loss: 2.4484\n",
      "Epoch   5 Batch  500/2536 - Train Accuracy: 0.5542, Validation Accuracy: 0.6339, Loss: 2.9923\n",
      "Epoch   5 Batch  600/2536 - Train Accuracy: 0.5875, Validation Accuracy: 0.6339, Loss: 2.8644\n",
      "Epoch   5 Batch  700/2536 - Train Accuracy: 0.5745, Validation Accuracy: 0.6339, Loss: 2.8996\n",
      "Epoch   5 Batch  800/2536 - Train Accuracy: 0.5721, Validation Accuracy: 0.6339, Loss: 3.0098\n",
      "Epoch   5 Batch  900/2536 - Train Accuracy: 0.4688, Validation Accuracy: 0.6339, Loss: 3.3032\n",
      "Epoch   5 Batch 1000/2536 - Train Accuracy: 0.5229, Validation Accuracy: 0.6339, Loss: 2.9895\n",
      "Epoch   5 Batch 1100/2536 - Train Accuracy: 0.3571, Validation Accuracy: 0.6339, Loss: 4.0442\n",
      "Epoch   5 Batch 1200/2536 - Train Accuracy: 0.4629, Validation Accuracy: 0.6339, Loss: 3.1599\n",
      "Epoch   5 Batch 1300/2536 - Train Accuracy: 0.7212, Validation Accuracy: 0.6339, Loss: 1.9859\n",
      "Epoch   5 Batch 1400/2536 - Train Accuracy: 0.4750, Validation Accuracy: 0.6339, Loss: 3.2828\n",
      "Epoch   5 Batch 1500/2536 - Train Accuracy: 0.6394, Validation Accuracy: 0.6339, Loss: 2.3005\n",
      "Epoch   5 Batch 1600/2536 - Train Accuracy: 0.5625, Validation Accuracy: 0.6339, Loss: 2.8165\n",
      "Epoch   5 Batch 1700/2536 - Train Accuracy: 0.6364, Validation Accuracy: 0.6339, Loss: 2.3455\n",
      "Epoch   5 Batch 1800/2536 - Train Accuracy: 0.7443, Validation Accuracy: 0.6339, Loss: 1.6978\n",
      "Epoch   5 Batch 1900/2536 - Train Accuracy: 0.5729, Validation Accuracy: 0.6339, Loss: 2.6958\n",
      "Epoch   5 Batch 2000/2536 - Train Accuracy: 0.5505, Validation Accuracy: 0.6339, Loss: 2.7429\n",
      "Epoch   5 Batch 2100/2536 - Train Accuracy: 0.4557, Validation Accuracy: 0.6339, Loss: 3.3443\n",
      "Epoch   5 Batch 2200/2536 - Train Accuracy: 0.6042, Validation Accuracy: 0.6339, Loss: 2.5743\n",
      "Epoch   5 Batch 2300/2536 - Train Accuracy: 0.3582, Validation Accuracy: 0.6339, Loss: 4.2587\n",
      "Epoch   5 Batch 2400/2536 - Train Accuracy: 0.4784, Validation Accuracy: 0.6339, Loss: 3.1919\n",
      "Epoch   5 Batch 2500/2536 - Train Accuracy: 0.3918, Validation Accuracy: 0.6339, Loss: 3.8887\n",
      "Epoch   6 Batch  100/2536 - Train Accuracy: 0.6449, Validation Accuracy: 0.6339, Loss: 2.4213\n",
      "Epoch   6 Batch  200/2536 - Train Accuracy: 0.7344, Validation Accuracy: 0.6339, Loss: 1.8911\n",
      "Epoch   6 Batch  300/2536 - Train Accuracy: 0.7277, Validation Accuracy: 0.6339, Loss: 1.7866\n",
      "Epoch   6 Batch  400/2536 - Train Accuracy: 0.6641, Validation Accuracy: 0.6339, Loss: 2.3443\n",
      "Epoch   6 Batch  500/2536 - Train Accuracy: 0.5646, Validation Accuracy: 0.6339, Loss: 2.8661\n",
      "Epoch   6 Batch  600/2536 - Train Accuracy: 0.5792, Validation Accuracy: 0.6339, Loss: 2.7669\n",
      "Epoch   6 Batch  700/2536 - Train Accuracy: 0.5841, Validation Accuracy: 0.6339, Loss: 2.7654\n",
      "Epoch   6 Batch  800/2536 - Train Accuracy: 0.5625, Validation Accuracy: 0.6339, Loss: 2.8996\n",
      "Epoch   6 Batch  900/2536 - Train Accuracy: 0.4754, Validation Accuracy: 0.6339, Loss: 3.1513\n",
      "Epoch   6 Batch 1000/2536 - Train Accuracy: 0.5229, Validation Accuracy: 0.6339, Loss: 2.8705\n",
      "Epoch   6 Batch 1100/2536 - Train Accuracy: 0.3482, Validation Accuracy: 0.6339, Loss: 3.8903\n",
      "Epoch   6 Batch 1200/2536 - Train Accuracy: 0.4844, Validation Accuracy: 0.6339, Loss: 3.0237\n",
      "Epoch   6 Batch 1300/2536 - Train Accuracy: 0.7188, Validation Accuracy: 0.6339, Loss: 1.8710\n",
      "Epoch   6 Batch 1400/2536 - Train Accuracy: 0.4938, Validation Accuracy: 0.6339, Loss: 3.1713\n",
      "Epoch   6 Batch 1500/2536 - Train Accuracy: 0.6514, Validation Accuracy: 0.6339, Loss: 2.1906\n",
      "Epoch   6 Batch 1600/2536 - Train Accuracy: 0.5625, Validation Accuracy: 0.6339, Loss: 2.7002\n",
      "Epoch   6 Batch 1700/2536 - Train Accuracy: 0.6364, Validation Accuracy: 0.6339, Loss: 2.2365\n",
      "Epoch   6 Batch 1800/2536 - Train Accuracy: 0.7500, Validation Accuracy: 0.6339, Loss: 1.6343\n",
      "Epoch   6 Batch 1900/2536 - Train Accuracy: 0.5703, Validation Accuracy: 0.6339, Loss: 2.5515\n",
      "Epoch   6 Batch 2000/2536 - Train Accuracy: 0.5601, Validation Accuracy: 0.6339, Loss: 2.6098\n",
      "Epoch   6 Batch 2100/2536 - Train Accuracy: 0.4583, Validation Accuracy: 0.6339, Loss: 3.1287\n",
      "Epoch   6 Batch 2200/2536 - Train Accuracy: 0.6167, Validation Accuracy: 0.6339, Loss: 2.4594\n",
      "Epoch   6 Batch 2300/2536 - Train Accuracy: 0.3630, Validation Accuracy: 0.6339, Loss: 4.0962\n",
      "Epoch   6 Batch 2400/2536 - Train Accuracy: 0.4832, Validation Accuracy: 0.6339, Loss: 3.0698\n",
      "Epoch   6 Batch 2500/2536 - Train Accuracy: 0.4207, Validation Accuracy: 0.6339, Loss: 3.7308\n",
      "Epoch   7 Batch  100/2536 - Train Accuracy: 0.6449, Validation Accuracy: 0.6339, Loss: 2.3220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7 Batch  200/2536 - Train Accuracy: 0.7366, Validation Accuracy: 0.6339, Loss: 1.8106\n",
      "Epoch   7 Batch  300/2536 - Train Accuracy: 0.7299, Validation Accuracy: 0.6339, Loss: 1.6975\n",
      "Epoch   7 Batch  400/2536 - Train Accuracy: 0.6641, Validation Accuracy: 0.6339, Loss: 2.2496\n",
      "Epoch   7 Batch  500/2536 - Train Accuracy: 0.5646, Validation Accuracy: 0.6339, Loss: 2.7763\n",
      "Epoch   7 Batch  600/2536 - Train Accuracy: 0.5854, Validation Accuracy: 0.6339, Loss: 2.6570\n",
      "Epoch   7 Batch  700/2536 - Train Accuracy: 0.5745, Validation Accuracy: 0.6339, Loss: 2.6655\n",
      "Epoch   7 Batch  800/2536 - Train Accuracy: 0.5721, Validation Accuracy: 0.6339, Loss: 2.8022\n",
      "Epoch   7 Batch  900/2536 - Train Accuracy: 0.4933, Validation Accuracy: 0.6339, Loss: 3.0163\n",
      "Epoch   7 Batch 1000/2536 - Train Accuracy: 0.5250, Validation Accuracy: 0.6339, Loss: 2.7557\n",
      "Epoch   7 Batch 1100/2536 - Train Accuracy: 0.3571, Validation Accuracy: 0.6339, Loss: 3.7385\n",
      "Epoch   7 Batch 1200/2536 - Train Accuracy: 0.4707, Validation Accuracy: 0.6339, Loss: 2.9042\n",
      "Epoch   7 Batch 1300/2536 - Train Accuracy: 0.7284, Validation Accuracy: 0.6339, Loss: 1.7715\n",
      "Epoch   7 Batch 1400/2536 - Train Accuracy: 0.5000, Validation Accuracy: 0.6339, Loss: 3.0548\n",
      "Epoch   7 Batch 1500/2536 - Train Accuracy: 0.6538, Validation Accuracy: 0.6339, Loss: 2.1037\n",
      "Epoch   7 Batch 1600/2536 - Train Accuracy: 0.5599, Validation Accuracy: 0.6339, Loss: 2.5812\n",
      "Epoch   7 Batch 1700/2536 - Train Accuracy: 0.6619, Validation Accuracy: 0.6339, Loss: 2.1262\n",
      "Epoch   7 Batch 1800/2536 - Train Accuracy: 0.7528, Validation Accuracy: 0.6339, Loss: 1.5808\n",
      "Epoch   7 Batch 1900/2536 - Train Accuracy: 0.5677, Validation Accuracy: 0.6339, Loss: 2.4238\n",
      "Epoch   7 Batch 2000/2536 - Train Accuracy: 0.5697, Validation Accuracy: 0.6339, Loss: 2.4774\n",
      "Epoch   7 Batch 2100/2536 - Train Accuracy: 0.4661, Validation Accuracy: 0.6339, Loss: 2.9165\n",
      "Epoch   7 Batch 2200/2536 - Train Accuracy: 0.6021, Validation Accuracy: 0.6339, Loss: 2.3553\n",
      "Epoch   7 Batch 2300/2536 - Train Accuracy: 0.3654, Validation Accuracy: 0.6339, Loss: 3.9718\n",
      "Epoch   7 Batch 2400/2536 - Train Accuracy: 0.4856, Validation Accuracy: 0.6339, Loss: 2.9413\n",
      "Epoch   7 Batch 2500/2536 - Train Accuracy: 0.4255, Validation Accuracy: 0.6339, Loss: 3.5923\n",
      "Epoch   8 Batch  100/2536 - Train Accuracy: 0.6449, Validation Accuracy: 0.6339, Loss: 2.2121\n",
      "Epoch   8 Batch  200/2536 - Train Accuracy: 0.7388, Validation Accuracy: 0.6339, Loss: 1.7585\n",
      "Epoch   8 Batch  300/2536 - Train Accuracy: 0.7254, Validation Accuracy: 0.6339, Loss: 1.6287\n",
      "Epoch   8 Batch  400/2536 - Train Accuracy: 0.6680, Validation Accuracy: 0.6339, Loss: 2.1679\n",
      "Epoch   8 Batch  500/2536 - Train Accuracy: 0.5708, Validation Accuracy: 0.6339, Loss: 2.6691\n",
      "Epoch   8 Batch  600/2536 - Train Accuracy: 0.5854, Validation Accuracy: 0.6339, Loss: 2.5317\n",
      "Epoch   8 Batch  700/2536 - Train Accuracy: 0.6010, Validation Accuracy: 0.6339, Loss: 2.5682\n",
      "Epoch   8 Batch  800/2536 - Train Accuracy: 0.5769, Validation Accuracy: 0.6339, Loss: 2.7189\n",
      "Epoch   8 Batch  900/2536 - Train Accuracy: 0.5022, Validation Accuracy: 0.6339, Loss: 2.8902\n",
      "Epoch   8 Batch 1000/2536 - Train Accuracy: 0.5354, Validation Accuracy: 0.6339, Loss: 2.6648\n",
      "Epoch   8 Batch 1100/2536 - Train Accuracy: 0.3594, Validation Accuracy: 0.6339, Loss: 3.6138\n",
      "Epoch   8 Batch 1200/2536 - Train Accuracy: 0.4668, Validation Accuracy: 0.6339, Loss: 2.7847\n",
      "Epoch   8 Batch 1300/2536 - Train Accuracy: 0.7284, Validation Accuracy: 0.6339, Loss: 1.6798\n",
      "Epoch   8 Batch 1400/2536 - Train Accuracy: 0.4917, Validation Accuracy: 0.6339, Loss: 2.9596\n",
      "Epoch   8 Batch 1500/2536 - Train Accuracy: 0.6659, Validation Accuracy: 0.6339, Loss: 2.0163\n",
      "Epoch   8 Batch 1600/2536 - Train Accuracy: 0.5781, Validation Accuracy: 0.6339, Loss: 2.4726\n",
      "Epoch   8 Batch 1700/2536 - Train Accuracy: 0.6648, Validation Accuracy: 0.6339, Loss: 2.0468\n",
      "Epoch   8 Batch 1800/2536 - Train Accuracy: 0.7528, Validation Accuracy: 0.6339, Loss: 1.5011\n",
      "Epoch   8 Batch 1900/2536 - Train Accuracy: 0.5807, Validation Accuracy: 0.6339, Loss: 2.3105\n",
      "Epoch   8 Batch 2000/2536 - Train Accuracy: 0.5745, Validation Accuracy: 0.6339, Loss: 2.3862\n",
      "Epoch   8 Batch 2100/2536 - Train Accuracy: 0.4766, Validation Accuracy: 0.6339, Loss: 2.7082\n",
      "Epoch   8 Batch 2200/2536 - Train Accuracy: 0.6021, Validation Accuracy: 0.6339, Loss: 2.2936\n",
      "Epoch   8 Batch 2300/2536 - Train Accuracy: 0.3678, Validation Accuracy: 0.6339, Loss: 3.8280\n",
      "Epoch   8 Batch 2400/2536 - Train Accuracy: 0.5024, Validation Accuracy: 0.6339, Loss: 2.8185\n",
      "Epoch   8 Batch 2500/2536 - Train Accuracy: 0.4303, Validation Accuracy: 0.6339, Loss: 3.4739\n",
      "Epoch   9 Batch  100/2536 - Train Accuracy: 0.6420, Validation Accuracy: 0.6339, Loss: 2.1297\n",
      "Epoch   9 Batch  200/2536 - Train Accuracy: 0.7366, Validation Accuracy: 0.6339, Loss: 1.7015\n",
      "Epoch   9 Batch  300/2536 - Train Accuracy: 0.7210, Validation Accuracy: 0.6339, Loss: 1.5679\n",
      "Epoch   9 Batch  400/2536 - Train Accuracy: 0.6777, Validation Accuracy: 0.6339, Loss: 2.0724\n",
      "Epoch   9 Batch  500/2536 - Train Accuracy: 0.5792, Validation Accuracy: 0.6339, Loss: 2.5798\n",
      "Epoch   9 Batch  600/2536 - Train Accuracy: 0.5875, Validation Accuracy: 0.6339, Loss: 2.4488\n",
      "Epoch   9 Batch  700/2536 - Train Accuracy: 0.5986, Validation Accuracy: 0.6339, Loss: 2.4886\n",
      "Epoch   9 Batch  800/2536 - Train Accuracy: 0.5697, Validation Accuracy: 0.6339, Loss: 2.6295\n",
      "Epoch   9 Batch  900/2536 - Train Accuracy: 0.4888, Validation Accuracy: 0.6339, Loss: 2.7677\n",
      "Epoch   9 Batch 1000/2536 - Train Accuracy: 0.5333, Validation Accuracy: 0.6339, Loss: 2.5873\n",
      "Epoch   9 Batch 1100/2536 - Train Accuracy: 0.3728, Validation Accuracy: 0.6339, Loss: 3.5063\n",
      "Epoch   9 Batch 1200/2536 - Train Accuracy: 0.4824, Validation Accuracy: 0.6339, Loss: 2.6722\n",
      "Epoch   9 Batch 1300/2536 - Train Accuracy: 0.7308, Validation Accuracy: 0.6339, Loss: 1.5969\n",
      "Epoch   9 Batch 1400/2536 - Train Accuracy: 0.5146, Validation Accuracy: 0.6339, Loss: 2.8555\n",
      "Epoch   9 Batch 1500/2536 - Train Accuracy: 0.6707, Validation Accuracy: 0.6339, Loss: 1.9300\n",
      "Epoch   9 Batch 1600/2536 - Train Accuracy: 0.5755, Validation Accuracy: 0.6339, Loss: 2.3767\n",
      "Epoch   9 Batch 1700/2536 - Train Accuracy: 0.6818, Validation Accuracy: 0.6339, Loss: 1.9481\n",
      "Epoch   9 Batch 1800/2536 - Train Accuracy: 0.7585, Validation Accuracy: 0.6339, Loss: 1.4375\n",
      "Epoch   9 Batch 1900/2536 - Train Accuracy: 0.6016, Validation Accuracy: 0.6339, Loss: 2.2177\n",
      "Epoch   9 Batch 2000/2536 - Train Accuracy: 0.5673, Validation Accuracy: 0.6339, Loss: 2.2995\n",
      "Epoch   9 Batch 2100/2536 - Train Accuracy: 0.4948, Validation Accuracy: 0.6339, Loss: 2.5502\n",
      "Epoch   9 Batch 2200/2536 - Train Accuracy: 0.6104, Validation Accuracy: 0.6339, Loss: 2.1850\n",
      "Epoch   9 Batch 2300/2536 - Train Accuracy: 0.3942, Validation Accuracy: 0.6339, Loss: 3.7282\n",
      "Epoch   9 Batch 2400/2536 - Train Accuracy: 0.4952, Validation Accuracy: 0.6339, Loss: 2.7415\n",
      "Epoch   9 Batch 2500/2536 - Train Accuracy: 0.4327, Validation Accuracy: 0.6339, Loss: 3.3691\n",
      "Epoch  10 Batch  100/2536 - Train Accuracy: 0.6506, Validation Accuracy: 0.6339, Loss: 2.0532\n",
      "Epoch  10 Batch  200/2536 - Train Accuracy: 0.7411, Validation Accuracy: 0.6339, Loss: 1.6416\n",
      "Epoch  10 Batch  300/2536 - Train Accuracy: 0.7411, Validation Accuracy: 0.6339, Loss: 1.5115\n",
      "Epoch  10 Batch  400/2536 - Train Accuracy: 0.6738, Validation Accuracy: 0.6339, Loss: 1.9991\n",
      "Epoch  10 Batch  500/2536 - Train Accuracy: 0.5750, Validation Accuracy: 0.6339, Loss: 2.4751\n",
      "Epoch  10 Batch  600/2536 - Train Accuracy: 0.5896, Validation Accuracy: 0.6339, Loss: 2.3622\n",
      "Epoch  10 Batch  700/2536 - Train Accuracy: 0.5962, Validation Accuracy: 0.6339, Loss: 2.4168\n",
      "Epoch  10 Batch  800/2536 - Train Accuracy: 0.5841, Validation Accuracy: 0.6339, Loss: 2.5467\n",
      "Epoch  10 Batch  900/2536 - Train Accuracy: 0.4955, Validation Accuracy: 0.6339, Loss: 2.6872\n",
      "Epoch  10 Batch 1000/2536 - Train Accuracy: 0.5458, Validation Accuracy: 0.6339, Loss: 2.4843\n",
      "Epoch  10 Batch 1100/2536 - Train Accuracy: 0.3728, Validation Accuracy: 0.6339, Loss: 3.3719\n",
      "Epoch  10 Batch 1200/2536 - Train Accuracy: 0.4883, Validation Accuracy: 0.6339, Loss: 2.5559\n",
      "Epoch  10 Batch 1300/2536 - Train Accuracy: 0.7308, Validation Accuracy: 0.6339, Loss: 1.5092\n",
      "Epoch  10 Batch 1400/2536 - Train Accuracy: 0.5208, Validation Accuracy: 0.6339, Loss: 2.7683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10 Batch 1500/2536 - Train Accuracy: 0.6683, Validation Accuracy: 0.6339, Loss: 1.8563\n",
      "Epoch  10 Batch 1600/2536 - Train Accuracy: 0.5703, Validation Accuracy: 0.6339, Loss: 2.2918\n",
      "Epoch  10 Batch 1700/2536 - Train Accuracy: 0.7074, Validation Accuracy: 0.6339, Loss: 1.8822\n",
      "Epoch  10 Batch 1800/2536 - Train Accuracy: 0.7585, Validation Accuracy: 0.6339, Loss: 1.3827\n",
      "Epoch  10 Batch 1900/2536 - Train Accuracy: 0.5990, Validation Accuracy: 0.6339, Loss: 2.1194\n",
      "Epoch  10 Batch 2000/2536 - Train Accuracy: 0.5793, Validation Accuracy: 0.6339, Loss: 2.2011\n",
      "Epoch  10 Batch 2100/2536 - Train Accuracy: 0.5182, Validation Accuracy: 0.6339, Loss: 2.3757\n",
      "Epoch  10 Batch 2200/2536 - Train Accuracy: 0.6208, Validation Accuracy: 0.6339, Loss: 2.1302\n",
      "Epoch  10 Batch 2300/2536 - Train Accuracy: 0.3966, Validation Accuracy: 0.6339, Loss: 3.6082\n",
      "Epoch  10 Batch 2400/2536 - Train Accuracy: 0.5216, Validation Accuracy: 0.6339, Loss: 2.6274\n",
      "Epoch  10 Batch 2500/2536 - Train Accuracy: 0.4279, Validation Accuracy: 0.6339, Loss: 3.2629\n",
      "Epoch  11 Batch  100/2536 - Train Accuracy: 0.6477, Validation Accuracy: 0.6339, Loss: 1.9631\n",
      "Epoch  11 Batch  200/2536 - Train Accuracy: 0.7522, Validation Accuracy: 0.6339, Loss: 1.5863\n",
      "Epoch  11 Batch  300/2536 - Train Accuracy: 0.7388, Validation Accuracy: 0.6339, Loss: 1.4436\n",
      "Epoch  11 Batch  400/2536 - Train Accuracy: 0.6777, Validation Accuracy: 0.6339, Loss: 1.9443\n",
      "Epoch  11 Batch  500/2536 - Train Accuracy: 0.5813, Validation Accuracy: 0.6339, Loss: 2.4044\n",
      "Epoch  11 Batch  600/2536 - Train Accuracy: 0.6146, Validation Accuracy: 0.6339, Loss: 2.2936\n",
      "Epoch  11 Batch  700/2536 - Train Accuracy: 0.6226, Validation Accuracy: 0.6339, Loss: 2.3280\n",
      "Epoch  11 Batch  800/2536 - Train Accuracy: 0.6010, Validation Accuracy: 0.6339, Loss: 2.4529\n",
      "Epoch  11 Batch  900/2536 - Train Accuracy: 0.5000, Validation Accuracy: 0.6339, Loss: 2.5964\n",
      "Epoch  11 Batch 1000/2536 - Train Accuracy: 0.5563, Validation Accuracy: 0.6339, Loss: 2.4324\n",
      "Epoch  11 Batch 1100/2536 - Train Accuracy: 0.4018, Validation Accuracy: 0.6339, Loss: 3.2654\n",
      "Epoch  11 Batch 1200/2536 - Train Accuracy: 0.5078, Validation Accuracy: 0.6339, Loss: 2.4631\n",
      "Epoch  11 Batch 1300/2536 - Train Accuracy: 0.7284, Validation Accuracy: 0.6339, Loss: 1.4348\n",
      "Epoch  11 Batch 1400/2536 - Train Accuracy: 0.5354, Validation Accuracy: 0.6339, Loss: 2.6631\n",
      "Epoch  11 Batch 1500/2536 - Train Accuracy: 0.6683, Validation Accuracy: 0.6339, Loss: 1.7956\n",
      "Epoch  11 Batch 1600/2536 - Train Accuracy: 0.5729, Validation Accuracy: 0.6339, Loss: 2.2217\n",
      "Epoch  11 Batch 1700/2536 - Train Accuracy: 0.6960, Validation Accuracy: 0.6339, Loss: 1.8040\n",
      "Epoch  11 Batch 1800/2536 - Train Accuracy: 0.7614, Validation Accuracy: 0.6339, Loss: 1.3332\n",
      "Epoch  11 Batch 1900/2536 - Train Accuracy: 0.5911, Validation Accuracy: 0.6339, Loss: 2.0345\n",
      "Epoch  11 Batch 2000/2536 - Train Accuracy: 0.5986, Validation Accuracy: 0.6339, Loss: 2.0992\n",
      "Epoch  11 Batch 2100/2536 - Train Accuracy: 0.5391, Validation Accuracy: 0.6339, Loss: 2.2260\n",
      "Epoch  11 Batch 2200/2536 - Train Accuracy: 0.6125, Validation Accuracy: 0.6339, Loss: 2.0557\n",
      "Epoch  11 Batch 2300/2536 - Train Accuracy: 0.4062, Validation Accuracy: 0.6339, Loss: 3.4868\n",
      "Epoch  11 Batch 2400/2536 - Train Accuracy: 0.5216, Validation Accuracy: 0.6339, Loss: 2.5538\n",
      "Epoch  11 Batch 2500/2536 - Train Accuracy: 0.4279, Validation Accuracy: 0.6339, Loss: 3.1560\n",
      "Epoch  12 Batch  100/2536 - Train Accuracy: 0.6676, Validation Accuracy: 0.6339, Loss: 1.8694\n",
      "Epoch  12 Batch  200/2536 - Train Accuracy: 0.7455, Validation Accuracy: 0.6339, Loss: 1.5400\n",
      "Epoch  12 Batch  300/2536 - Train Accuracy: 0.7455, Validation Accuracy: 0.6339, Loss: 1.3986\n",
      "Epoch  12 Batch  400/2536 - Train Accuracy: 0.6699, Validation Accuracy: 0.6339, Loss: 1.8743\n",
      "Epoch  12 Batch  500/2536 - Train Accuracy: 0.5833, Validation Accuracy: 0.6339, Loss: 2.3290\n",
      "Epoch  12 Batch  600/2536 - Train Accuracy: 0.6125, Validation Accuracy: 0.6339, Loss: 2.2217\n",
      "Epoch  12 Batch  700/2536 - Train Accuracy: 0.5986, Validation Accuracy: 0.6339, Loss: 2.2433\n",
      "Epoch  12 Batch  800/2536 - Train Accuracy: 0.6034, Validation Accuracy: 0.6339, Loss: 2.3761\n",
      "Epoch  12 Batch  900/2536 - Train Accuracy: 0.5089, Validation Accuracy: 0.6339, Loss: 2.4966\n",
      "Epoch  12 Batch 1000/2536 - Train Accuracy: 0.5646, Validation Accuracy: 0.6339, Loss: 2.3295\n",
      "Epoch  12 Batch 1100/2536 - Train Accuracy: 0.4085, Validation Accuracy: 0.6339, Loss: 3.1808\n",
      "Epoch  12 Batch 1200/2536 - Train Accuracy: 0.5000, Validation Accuracy: 0.6339, Loss: 2.3695\n",
      "Epoch  12 Batch 1300/2536 - Train Accuracy: 0.7380, Validation Accuracy: 0.6339, Loss: 1.3512\n",
      "Epoch  12 Batch 1400/2536 - Train Accuracy: 0.5312, Validation Accuracy: 0.6339, Loss: 2.5974\n",
      "Epoch  12 Batch 1500/2536 - Train Accuracy: 0.6827, Validation Accuracy: 0.6339, Loss: 1.7226\n",
      "Epoch  12 Batch 1600/2536 - Train Accuracy: 0.5833, Validation Accuracy: 0.6339, Loss: 2.1453\n",
      "Epoch  12 Batch 1700/2536 - Train Accuracy: 0.7017, Validation Accuracy: 0.6339, Loss: 1.7237\n",
      "Epoch  12 Batch 1800/2536 - Train Accuracy: 0.7585, Validation Accuracy: 0.6339, Loss: 1.2825\n",
      "Epoch  12 Batch 1900/2536 - Train Accuracy: 0.6016, Validation Accuracy: 0.6339, Loss: 1.9542\n",
      "Epoch  12 Batch 2000/2536 - Train Accuracy: 0.5841, Validation Accuracy: 0.6339, Loss: 2.0387\n",
      "Epoch  12 Batch 2100/2536 - Train Accuracy: 0.5365, Validation Accuracy: 0.6339, Loss: 2.0849\n",
      "Epoch  12 Batch 2200/2536 - Train Accuracy: 0.6271, Validation Accuracy: 0.6339, Loss: 1.9692\n",
      "Epoch  12 Batch 2300/2536 - Train Accuracy: 0.4111, Validation Accuracy: 0.6339, Loss: 3.3881\n",
      "Epoch  12 Batch 2400/2536 - Train Accuracy: 0.5192, Validation Accuracy: 0.6339, Loss: 2.4696\n",
      "Epoch  12 Batch 2500/2536 - Train Accuracy: 0.4519, Validation Accuracy: 0.6339, Loss: 3.0774\n",
      "Epoch  13 Batch  100/2536 - Train Accuracy: 0.6790, Validation Accuracy: 0.6339, Loss: 1.7985\n",
      "Epoch  13 Batch  200/2536 - Train Accuracy: 0.7545, Validation Accuracy: 0.6339, Loss: 1.4825\n",
      "Epoch  13 Batch  300/2536 - Train Accuracy: 0.7500, Validation Accuracy: 0.6339, Loss: 1.3662\n",
      "Epoch  13 Batch  400/2536 - Train Accuracy: 0.6758, Validation Accuracy: 0.6339, Loss: 1.8088\n",
      "Epoch  13 Batch  500/2536 - Train Accuracy: 0.5833, Validation Accuracy: 0.6339, Loss: 2.2636\n",
      "Epoch  13 Batch  600/2536 - Train Accuracy: 0.6167, Validation Accuracy: 0.6339, Loss: 2.1538\n",
      "Epoch  13 Batch  700/2536 - Train Accuracy: 0.6130, Validation Accuracy: 0.6339, Loss: 2.1774\n",
      "Epoch  13 Batch  800/2536 - Train Accuracy: 0.5962, Validation Accuracy: 0.6339, Loss: 2.2876\n",
      "Epoch  13 Batch  900/2536 - Train Accuracy: 0.5402, Validation Accuracy: 0.6339, Loss: 2.4395\n",
      "Epoch  13 Batch 1000/2536 - Train Accuracy: 0.5792, Validation Accuracy: 0.6339, Loss: 2.2716\n",
      "Epoch  13 Batch 1100/2536 - Train Accuracy: 0.4174, Validation Accuracy: 0.6339, Loss: 3.0764\n",
      "Epoch  13 Batch 1200/2536 - Train Accuracy: 0.5117, Validation Accuracy: 0.6339, Loss: 2.2932\n",
      "Epoch  13 Batch 1300/2536 - Train Accuracy: 0.7428, Validation Accuracy: 0.6339, Loss: 1.2784\n",
      "Epoch  13 Batch 1400/2536 - Train Accuracy: 0.5312, Validation Accuracy: 0.6339, Loss: 2.4918\n",
      "Epoch  13 Batch 1500/2536 - Train Accuracy: 0.6875, Validation Accuracy: 0.6339, Loss: 1.6796\n",
      "Epoch  13 Batch 1600/2536 - Train Accuracy: 0.6068, Validation Accuracy: 0.6339, Loss: 2.0705\n",
      "Epoch  13 Batch 1700/2536 - Train Accuracy: 0.7188, Validation Accuracy: 0.6339, Loss: 1.6737\n",
      "Epoch  13 Batch 1800/2536 - Train Accuracy: 0.7699, Validation Accuracy: 0.6339, Loss: 1.2279\n",
      "Epoch  13 Batch 1900/2536 - Train Accuracy: 0.6250, Validation Accuracy: 0.6339, Loss: 1.8847\n",
      "Epoch  13 Batch 2000/2536 - Train Accuracy: 0.5986, Validation Accuracy: 0.6339, Loss: 1.9525\n",
      "Epoch  13 Batch 2100/2536 - Train Accuracy: 0.5599, Validation Accuracy: 0.6339, Loss: 1.9406\n",
      "Epoch  13 Batch 2200/2536 - Train Accuracy: 0.6479, Validation Accuracy: 0.6339, Loss: 1.9140\n",
      "Epoch  13 Batch 2300/2536 - Train Accuracy: 0.4111, Validation Accuracy: 0.6339, Loss: 3.2994\n",
      "Epoch  13 Batch 2400/2536 - Train Accuracy: 0.5505, Validation Accuracy: 0.6339, Loss: 2.4050\n",
      "Epoch  13 Batch 2500/2536 - Train Accuracy: 0.4111, Validation Accuracy: 0.6339, Loss: 2.9727\n",
      "Epoch  14 Batch  100/2536 - Train Accuracy: 0.6847, Validation Accuracy: 0.6339, Loss: 1.7206\n",
      "Epoch  14 Batch  200/2536 - Train Accuracy: 0.7656, Validation Accuracy: 0.6339, Loss: 1.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  14 Batch  300/2536 - Train Accuracy: 0.7545, Validation Accuracy: 0.6339, Loss: 1.3022\n",
      "Epoch  14 Batch  400/2536 - Train Accuracy: 0.6797, Validation Accuracy: 0.6339, Loss: 1.7769\n",
      "Epoch  14 Batch  500/2536 - Train Accuracy: 0.5896, Validation Accuracy: 0.6339, Loss: 2.1995\n",
      "Epoch  14 Batch  600/2536 - Train Accuracy: 0.6208, Validation Accuracy: 0.6339, Loss: 2.1051\n",
      "Epoch  14 Batch  700/2536 - Train Accuracy: 0.6130, Validation Accuracy: 0.6339, Loss: 2.1230\n",
      "Epoch  14 Batch  800/2536 - Train Accuracy: 0.6226, Validation Accuracy: 0.6339, Loss: 2.2123\n",
      "Epoch  14 Batch  900/2536 - Train Accuracy: 0.5156, Validation Accuracy: 0.6339, Loss: 2.3622\n",
      "Epoch  14 Batch 1000/2536 - Train Accuracy: 0.5792, Validation Accuracy: 0.6339, Loss: 2.2242\n",
      "Epoch  14 Batch 1100/2536 - Train Accuracy: 0.4062, Validation Accuracy: 0.6339, Loss: 2.9828\n",
      "Epoch  14 Batch 1200/2536 - Train Accuracy: 0.5410, Validation Accuracy: 0.6339, Loss: 2.1906\n",
      "Epoch  14 Batch 1300/2536 - Train Accuracy: 0.7548, Validation Accuracy: 0.6339, Loss: 1.2042\n",
      "Epoch  14 Batch 1400/2536 - Train Accuracy: 0.5500, Validation Accuracy: 0.6339, Loss: 2.4273\n",
      "Epoch  14 Batch 1500/2536 - Train Accuracy: 0.6755, Validation Accuracy: 0.6339, Loss: 1.6196\n",
      "Epoch  14 Batch 1600/2536 - Train Accuracy: 0.6276, Validation Accuracy: 0.6339, Loss: 1.9921\n",
      "Epoch  14 Batch 1700/2536 - Train Accuracy: 0.7188, Validation Accuracy: 0.6339, Loss: 1.6117\n",
      "Epoch  14 Batch 1800/2536 - Train Accuracy: 0.7670, Validation Accuracy: 0.6339, Loss: 1.1973\n",
      "Epoch  14 Batch 1900/2536 - Train Accuracy: 0.6432, Validation Accuracy: 0.6339, Loss: 1.8205\n",
      "Epoch  14 Batch 2000/2536 - Train Accuracy: 0.6082, Validation Accuracy: 0.6339, Loss: 1.8992\n",
      "Epoch  14 Batch 2100/2536 - Train Accuracy: 0.5755, Validation Accuracy: 0.6339, Loss: 1.8075\n",
      "Epoch  14 Batch 2200/2536 - Train Accuracy: 0.6396, Validation Accuracy: 0.6339, Loss: 1.8724\n",
      "Epoch  14 Batch 2300/2536 - Train Accuracy: 0.4038, Validation Accuracy: 0.6339, Loss: 3.2069\n",
      "Epoch  14 Batch 2400/2536 - Train Accuracy: 0.5553, Validation Accuracy: 0.6339, Loss: 2.3418\n",
      "Epoch  14 Batch 2500/2536 - Train Accuracy: 0.4255, Validation Accuracy: 0.6339, Loss: 2.8851\n",
      "Epoch  15 Batch  100/2536 - Train Accuracy: 0.7074, Validation Accuracy: 0.6339, Loss: 1.6376\n",
      "Epoch  15 Batch  200/2536 - Train Accuracy: 0.7634, Validation Accuracy: 0.6339, Loss: 1.4134\n",
      "Epoch  15 Batch  300/2536 - Train Accuracy: 0.7656, Validation Accuracy: 0.6339, Loss: 1.2671\n",
      "Epoch  15 Batch  400/2536 - Train Accuracy: 0.6914, Validation Accuracy: 0.6339, Loss: 1.7004\n",
      "Epoch  15 Batch  500/2536 - Train Accuracy: 0.6104, Validation Accuracy: 0.6339, Loss: 2.1285\n",
      "Epoch  15 Batch  600/2536 - Train Accuracy: 0.6271, Validation Accuracy: 0.6339, Loss: 2.0289\n",
      "Epoch  15 Batch  700/2536 - Train Accuracy: 0.6082, Validation Accuracy: 0.6339, Loss: 2.0616\n",
      "Epoch  15 Batch  800/2536 - Train Accuracy: 0.6154, Validation Accuracy: 0.6339, Loss: 2.1679\n",
      "Epoch  15 Batch  900/2536 - Train Accuracy: 0.5312, Validation Accuracy: 0.6339, Loss: 2.2809\n",
      "Epoch  15 Batch 1000/2536 - Train Accuracy: 0.5771, Validation Accuracy: 0.6339, Loss: 2.1413\n",
      "Epoch  15 Batch 1100/2536 - Train Accuracy: 0.4129, Validation Accuracy: 0.6339, Loss: 2.8751\n",
      "Epoch  15 Batch 1200/2536 - Train Accuracy: 0.5391, Validation Accuracy: 0.6339, Loss: 2.1386\n",
      "Epoch  15 Batch 1300/2536 - Train Accuracy: 0.7572, Validation Accuracy: 0.6339, Loss: 1.1329\n",
      "Epoch  15 Batch 1400/2536 - Train Accuracy: 0.5542, Validation Accuracy: 0.6339, Loss: 2.3406\n",
      "Epoch  15 Batch 1500/2536 - Train Accuracy: 0.6923, Validation Accuracy: 0.6339, Loss: 1.5629\n",
      "Epoch  15 Batch 1600/2536 - Train Accuracy: 0.6198, Validation Accuracy: 0.6339, Loss: 1.9384\n",
      "Epoch  15 Batch 1700/2536 - Train Accuracy: 0.7443, Validation Accuracy: 0.6339, Loss: 1.5561\n",
      "Epoch  15 Batch 1800/2536 - Train Accuracy: 0.7699, Validation Accuracy: 0.6339, Loss: 1.1477\n",
      "Epoch  15 Batch 1900/2536 - Train Accuracy: 0.6693, Validation Accuracy: 0.6339, Loss: 1.7278\n",
      "Epoch  15 Batch 2000/2536 - Train Accuracy: 0.6082, Validation Accuracy: 0.6339, Loss: 1.8117\n",
      "Epoch  15 Batch 2100/2536 - Train Accuracy: 0.5938, Validation Accuracy: 0.6339, Loss: 1.6737\n",
      "Epoch  15 Batch 2200/2536 - Train Accuracy: 0.6646, Validation Accuracy: 0.6339, Loss: 1.8063\n",
      "Epoch  15 Batch 2300/2536 - Train Accuracy: 0.4231, Validation Accuracy: 0.6339, Loss: 3.1216\n",
      "Epoch  15 Batch 2400/2536 - Train Accuracy: 0.5697, Validation Accuracy: 0.6339, Loss: 2.2462\n",
      "Epoch  15 Batch 2500/2536 - Train Accuracy: 0.4784, Validation Accuracy: 0.6339, Loss: 2.7958\n",
      "Epoch  16 Batch  100/2536 - Train Accuracy: 0.6903, Validation Accuracy: 0.6339, Loss: 1.5771\n",
      "Epoch  16 Batch  200/2536 - Train Accuracy: 0.7679, Validation Accuracy: 0.6339, Loss: 1.3629\n",
      "Epoch  16 Batch  300/2536 - Train Accuracy: 0.7723, Validation Accuracy: 0.6339, Loss: 1.2173\n",
      "Epoch  16 Batch  400/2536 - Train Accuracy: 0.6973, Validation Accuracy: 0.6339, Loss: 1.6604\n",
      "Epoch  16 Batch  500/2536 - Train Accuracy: 0.6062, Validation Accuracy: 0.6339, Loss: 2.0509\n",
      "Epoch  16 Batch  600/2536 - Train Accuracy: 0.6271, Validation Accuracy: 0.6339, Loss: 1.9759\n",
      "Epoch  16 Batch  700/2536 - Train Accuracy: 0.6250, Validation Accuracy: 0.6339, Loss: 1.9982\n",
      "Epoch  16 Batch  800/2536 - Train Accuracy: 0.6346, Validation Accuracy: 0.6339, Loss: 2.1264\n",
      "Epoch  16 Batch  900/2536 - Train Accuracy: 0.5424, Validation Accuracy: 0.6339, Loss: 2.2321\n",
      "Epoch  16 Batch 1000/2536 - Train Accuracy: 0.5667, Validation Accuracy: 0.6339, Loss: 2.0736\n",
      "Epoch  16 Batch 1100/2536 - Train Accuracy: 0.4241, Validation Accuracy: 0.6339, Loss: 2.8110\n",
      "Epoch  16 Batch 1200/2536 - Train Accuracy: 0.5625, Validation Accuracy: 0.6339, Loss: 2.0534\n",
      "Epoch  16 Batch 1300/2536 - Train Accuracy: 0.7764, Validation Accuracy: 0.6339, Loss: 1.0556\n",
      "Epoch  16 Batch 1400/2536 - Train Accuracy: 0.5521, Validation Accuracy: 0.6339, Loss: 2.2938\n",
      "Epoch  16 Batch 1500/2536 - Train Accuracy: 0.6971, Validation Accuracy: 0.6339, Loss: 1.5195\n",
      "Epoch  16 Batch 1600/2536 - Train Accuracy: 0.6328, Validation Accuracy: 0.6339, Loss: 1.8530\n",
      "Epoch  16 Batch 1700/2536 - Train Accuracy: 0.7216, Validation Accuracy: 0.6339, Loss: 1.4824\n",
      "Epoch  16 Batch 1800/2536 - Train Accuracy: 0.7727, Validation Accuracy: 0.6339, Loss: 1.1167\n",
      "Epoch  16 Batch 1900/2536 - Train Accuracy: 0.6536, Validation Accuracy: 0.6339, Loss: 1.6807\n",
      "Epoch  16 Batch 2000/2536 - Train Accuracy: 0.6082, Validation Accuracy: 0.6339, Loss: 1.7803\n",
      "Epoch  16 Batch 2100/2536 - Train Accuracy: 0.6016, Validation Accuracy: 0.6339, Loss: 1.5234\n",
      "Epoch  16 Batch 2200/2536 - Train Accuracy: 0.6625, Validation Accuracy: 0.6339, Loss: 1.7667\n",
      "Epoch  16 Batch 2300/2536 - Train Accuracy: 0.4159, Validation Accuracy: 0.6339, Loss: 3.0055\n",
      "Epoch  16 Batch 2400/2536 - Train Accuracy: 0.5577, Validation Accuracy: 0.6339, Loss: 2.1897\n",
      "Epoch  16 Batch 2500/2536 - Train Accuracy: 0.4760, Validation Accuracy: 0.6339, Loss: 2.7597\n",
      "Epoch  17 Batch  100/2536 - Train Accuracy: 0.7074, Validation Accuracy: 0.6339, Loss: 1.5071\n",
      "Epoch  17 Batch  200/2536 - Train Accuracy: 0.7701, Validation Accuracy: 0.6339, Loss: 1.3298\n",
      "Epoch  17 Batch  300/2536 - Train Accuracy: 0.7656, Validation Accuracy: 0.6339, Loss: 1.1713\n",
      "Epoch  17 Batch  400/2536 - Train Accuracy: 0.6973, Validation Accuracy: 0.6339, Loss: 1.5989\n",
      "Epoch  17 Batch  500/2536 - Train Accuracy: 0.6021, Validation Accuracy: 0.6339, Loss: 2.0083\n",
      "Epoch  17 Batch  600/2536 - Train Accuracy: 0.6333, Validation Accuracy: 0.6339, Loss: 1.9186\n",
      "Epoch  17 Batch  700/2536 - Train Accuracy: 0.6154, Validation Accuracy: 0.6339, Loss: 1.9585\n",
      "Epoch  17 Batch  800/2536 - Train Accuracy: 0.6082, Validation Accuracy: 0.6339, Loss: 2.0548\n",
      "Epoch  17 Batch  900/2536 - Train Accuracy: 0.5580, Validation Accuracy: 0.6339, Loss: 2.1595\n",
      "Epoch  17 Batch 1000/2536 - Train Accuracy: 0.5813, Validation Accuracy: 0.6339, Loss: 2.0141\n",
      "Epoch  17 Batch 1100/2536 - Train Accuracy: 0.4241, Validation Accuracy: 0.6339, Loss: 2.7946\n",
      "Epoch  17 Batch 1200/2536 - Train Accuracy: 0.5410, Validation Accuracy: 0.6339, Loss: 1.9994\n",
      "Epoch  17 Batch 1300/2536 - Train Accuracy: 0.7861, Validation Accuracy: 0.6339, Loss: 1.0049\n",
      "Epoch  17 Batch 1400/2536 - Train Accuracy: 0.5625, Validation Accuracy: 0.6339, Loss: 2.2047\n",
      "Epoch  17 Batch 1500/2536 - Train Accuracy: 0.7043, Validation Accuracy: 0.6339, Loss: 1.4628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  17 Batch 1600/2536 - Train Accuracy: 0.6458, Validation Accuracy: 0.6339, Loss: 1.8010\n",
      "Epoch  17 Batch 1700/2536 - Train Accuracy: 0.7415, Validation Accuracy: 0.6339, Loss: 1.4387\n",
      "Epoch  17 Batch 1800/2536 - Train Accuracy: 0.7756, Validation Accuracy: 0.6339, Loss: 1.0642\n",
      "Epoch  17 Batch 1900/2536 - Train Accuracy: 0.6719, Validation Accuracy: 0.6339, Loss: 1.6142\n",
      "Epoch  17 Batch 2000/2536 - Train Accuracy: 0.6106, Validation Accuracy: 0.6339, Loss: 1.6985\n",
      "Epoch  17 Batch 2100/2536 - Train Accuracy: 0.6224, Validation Accuracy: 0.6339, Loss: 1.4169\n",
      "Epoch  17 Batch 2200/2536 - Train Accuracy: 0.6542, Validation Accuracy: 0.6339, Loss: 1.6999\n",
      "Epoch  17 Batch 2300/2536 - Train Accuracy: 0.4279, Validation Accuracy: 0.6339, Loss: 2.9558\n",
      "Epoch  17 Batch 2400/2536 - Train Accuracy: 0.5817, Validation Accuracy: 0.6339, Loss: 2.1278\n",
      "Epoch  17 Batch 2500/2536 - Train Accuracy: 0.4832, Validation Accuracy: 0.6339, Loss: 2.6491\n",
      "Epoch  18 Batch  100/2536 - Train Accuracy: 0.7188, Validation Accuracy: 0.6339, Loss: 1.4505\n",
      "Epoch  18 Batch  200/2536 - Train Accuracy: 0.7790, Validation Accuracy: 0.6339, Loss: 1.3104\n",
      "Epoch  18 Batch  300/2536 - Train Accuracy: 0.7879, Validation Accuracy: 0.6339, Loss: 1.1484\n",
      "Epoch  18 Batch  400/2536 - Train Accuracy: 0.6895, Validation Accuracy: 0.6339, Loss: 1.5688\n",
      "Epoch  18 Batch  500/2536 - Train Accuracy: 0.6208, Validation Accuracy: 0.6339, Loss: 1.9546\n",
      "Epoch  18 Batch  600/2536 - Train Accuracy: 0.6417, Validation Accuracy: 0.6339, Loss: 1.8482\n",
      "Epoch  18 Batch  700/2536 - Train Accuracy: 0.6370, Validation Accuracy: 0.6339, Loss: 1.8937\n",
      "Epoch  18 Batch  800/2536 - Train Accuracy: 0.6130, Validation Accuracy: 0.6339, Loss: 1.9780\n",
      "Epoch  18 Batch  900/2536 - Train Accuracy: 0.5625, Validation Accuracy: 0.6339, Loss: 2.0937\n",
      "Epoch  18 Batch 1000/2536 - Train Accuracy: 0.5854, Validation Accuracy: 0.6339, Loss: 1.9473\n",
      "Epoch  18 Batch 1100/2536 - Train Accuracy: 0.4353, Validation Accuracy: 0.6339, Loss: 2.6746\n",
      "Epoch  18 Batch 1200/2536 - Train Accuracy: 0.5371, Validation Accuracy: 0.6339, Loss: 1.9100\n",
      "Epoch  18 Batch 1300/2536 - Train Accuracy: 0.7837, Validation Accuracy: 0.6339, Loss: 0.9390\n",
      "Epoch  18 Batch 1400/2536 - Train Accuracy: 0.5729, Validation Accuracy: 0.6339, Loss: 2.1611\n",
      "Epoch  18 Batch 1500/2536 - Train Accuracy: 0.7212, Validation Accuracy: 0.6339, Loss: 1.4058\n",
      "Epoch  18 Batch 1600/2536 - Train Accuracy: 0.6641, Validation Accuracy: 0.6339, Loss: 1.7482\n",
      "Epoch  18 Batch 1700/2536 - Train Accuracy: 0.7670, Validation Accuracy: 0.6339, Loss: 1.3896\n",
      "Epoch  18 Batch 1800/2536 - Train Accuracy: 0.7756, Validation Accuracy: 0.6339, Loss: 1.0253\n",
      "Epoch  18 Batch 1900/2536 - Train Accuracy: 0.6823, Validation Accuracy: 0.6339, Loss: 1.5446\n",
      "Epoch  18 Batch 2000/2536 - Train Accuracy: 0.6322, Validation Accuracy: 0.6339, Loss: 1.6342\n",
      "Epoch  18 Batch 2100/2536 - Train Accuracy: 0.6250, Validation Accuracy: 0.6339, Loss: 1.3102\n",
      "Epoch  18 Batch 2200/2536 - Train Accuracy: 0.6542, Validation Accuracy: 0.6339, Loss: 1.6401\n",
      "Epoch  18 Batch 2300/2536 - Train Accuracy: 0.4399, Validation Accuracy: 0.6339, Loss: 2.8708\n",
      "Epoch  18 Batch 2400/2536 - Train Accuracy: 0.5865, Validation Accuracy: 0.6339, Loss: 2.0693\n",
      "Epoch  18 Batch 2500/2536 - Train Accuracy: 0.4784, Validation Accuracy: 0.6339, Loss: 2.6017\n",
      "Epoch  19 Batch  100/2536 - Train Accuracy: 0.7216, Validation Accuracy: 0.6339, Loss: 1.3648\n",
      "Epoch  19 Batch  200/2536 - Train Accuracy: 0.7746, Validation Accuracy: 0.6339, Loss: 1.2447\n",
      "Epoch  19 Batch  300/2536 - Train Accuracy: 0.7746, Validation Accuracy: 0.6339, Loss: 1.1047\n",
      "Epoch  19 Batch  400/2536 - Train Accuracy: 0.6953, Validation Accuracy: 0.6339, Loss: 1.4995\n",
      "Epoch  19 Batch  500/2536 - Train Accuracy: 0.6083, Validation Accuracy: 0.6339, Loss: 1.8869\n",
      "Epoch  19 Batch  600/2536 - Train Accuracy: 0.6604, Validation Accuracy: 0.6339, Loss: 1.7952\n",
      "Epoch  19 Batch  700/2536 - Train Accuracy: 0.6274, Validation Accuracy: 0.6339, Loss: 1.8528\n",
      "Epoch  19 Batch  800/2536 - Train Accuracy: 0.6394, Validation Accuracy: 0.6339, Loss: 1.9375\n",
      "Epoch  19 Batch  900/2536 - Train Accuracy: 0.5580, Validation Accuracy: 0.6339, Loss: 2.0353\n",
      "Epoch  19 Batch 1000/2536 - Train Accuracy: 0.5854, Validation Accuracy: 0.6339, Loss: 1.8990\n",
      "Epoch  19 Batch 1100/2536 - Train Accuracy: 0.4375, Validation Accuracy: 0.6339, Loss: 2.6097\n",
      "Epoch  19 Batch 1200/2536 - Train Accuracy: 0.5527, Validation Accuracy: 0.6339, Loss: 1.8826\n",
      "Epoch  19 Batch 1300/2536 - Train Accuracy: 0.8125, Validation Accuracy: 0.6339, Loss: 0.8685\n",
      "Epoch  19 Batch 1400/2536 - Train Accuracy: 0.5896, Validation Accuracy: 0.6339, Loss: 2.1075\n",
      "Epoch  19 Batch 1500/2536 - Train Accuracy: 0.7139, Validation Accuracy: 0.6339, Loss: 1.3606\n",
      "Epoch  19 Batch 1600/2536 - Train Accuracy: 0.6771, Validation Accuracy: 0.6339, Loss: 1.6829\n",
      "Epoch  19 Batch 1700/2536 - Train Accuracy: 0.7614, Validation Accuracy: 0.6339, Loss: 1.3230\n",
      "Epoch  19 Batch 1800/2536 - Train Accuracy: 0.8153, Validation Accuracy: 0.6339, Loss: 0.9917\n",
      "Epoch  19 Batch 1900/2536 - Train Accuracy: 0.6771, Validation Accuracy: 0.6339, Loss: 1.4959\n",
      "Epoch  19 Batch 2000/2536 - Train Accuracy: 0.6322, Validation Accuracy: 0.6339, Loss: 1.5992\n",
      "Epoch  19 Batch 2100/2536 - Train Accuracy: 0.6510, Validation Accuracy: 0.6339, Loss: 1.1885\n",
      "Epoch  19 Batch 2200/2536 - Train Accuracy: 0.6792, Validation Accuracy: 0.6339, Loss: 1.6088\n",
      "Epoch  19 Batch 2300/2536 - Train Accuracy: 0.4399, Validation Accuracy: 0.6339, Loss: 2.7833\n",
      "Epoch  19 Batch 2400/2536 - Train Accuracy: 0.5913, Validation Accuracy: 0.6339, Loss: 2.0058\n",
      "Epoch  19 Batch 2500/2536 - Train Accuracy: 0.4904, Validation Accuracy: 0.6339, Loss: 2.5412\n",
      "Epoch  20 Batch  100/2536 - Train Accuracy: 0.7330, Validation Accuracy: 0.6339, Loss: 1.3255\n",
      "Epoch  20 Batch  200/2536 - Train Accuracy: 0.7679, Validation Accuracy: 0.6339, Loss: 1.2010\n",
      "Epoch  20 Batch  300/2536 - Train Accuracy: 0.7768, Validation Accuracy: 0.6339, Loss: 1.0590\n",
      "Epoch  20 Batch  400/2536 - Train Accuracy: 0.6953, Validation Accuracy: 0.6339, Loss: 1.4659\n",
      "Epoch  20 Batch  500/2536 - Train Accuracy: 0.6146, Validation Accuracy: 0.6339, Loss: 1.8559\n",
      "Epoch  20 Batch  600/2536 - Train Accuracy: 0.6521, Validation Accuracy: 0.6339, Loss: 1.7433\n",
      "Epoch  20 Batch  700/2536 - Train Accuracy: 0.6346, Validation Accuracy: 0.6339, Loss: 1.7901\n",
      "Epoch  20 Batch  800/2536 - Train Accuracy: 0.6346, Validation Accuracy: 0.6339, Loss: 1.8846\n",
      "Epoch  20 Batch  900/2536 - Train Accuracy: 0.5603, Validation Accuracy: 0.6339, Loss: 1.9880\n",
      "Epoch  20 Batch 1000/2536 - Train Accuracy: 0.5917, Validation Accuracy: 0.6339, Loss: 1.8505\n",
      "Epoch  20 Batch 1100/2536 - Train Accuracy: 0.4464, Validation Accuracy: 0.6339, Loss: 2.5523\n",
      "Epoch  20 Batch 1200/2536 - Train Accuracy: 0.5664, Validation Accuracy: 0.6339, Loss: 1.8035\n",
      "Epoch  20 Batch 1300/2536 - Train Accuracy: 0.8053, Validation Accuracy: 0.6339, Loss: 0.8125\n",
      "Epoch  20 Batch 1400/2536 - Train Accuracy: 0.5771, Validation Accuracy: 0.6339, Loss: 2.0392\n",
      "Epoch  20 Batch 1500/2536 - Train Accuracy: 0.7043, Validation Accuracy: 0.6339, Loss: 1.3267\n",
      "Epoch  20 Batch 1600/2536 - Train Accuracy: 0.6510, Validation Accuracy: 0.6339, Loss: 1.6191\n",
      "Epoch  20 Batch 1700/2536 - Train Accuracy: 0.7727, Validation Accuracy: 0.6339, Loss: 1.2767\n",
      "Epoch  20 Batch 1800/2536 - Train Accuracy: 0.8097, Validation Accuracy: 0.6339, Loss: 0.9530\n",
      "Epoch  20 Batch 1900/2536 - Train Accuracy: 0.6745, Validation Accuracy: 0.6339, Loss: 1.4346\n",
      "Epoch  20 Batch 2000/2536 - Train Accuracy: 0.6538, Validation Accuracy: 0.6339, Loss: 1.5330\n",
      "Epoch  20 Batch 2100/2536 - Train Accuracy: 0.6302, Validation Accuracy: 0.6339, Loss: 1.1128\n",
      "Epoch  20 Batch 2200/2536 - Train Accuracy: 0.6813, Validation Accuracy: 0.6339, Loss: 1.5563\n",
      "Epoch  20 Batch 2300/2536 - Train Accuracy: 0.4663, Validation Accuracy: 0.6339, Loss: 2.7157\n",
      "Epoch  20 Batch 2400/2536 - Train Accuracy: 0.6082, Validation Accuracy: 0.6339, Loss: 1.9713\n",
      "Epoch  20 Batch 2500/2536 - Train Accuracy: 0.4976, Validation Accuracy: 0.6339, Loss: 2.4590\n",
      "Epoch  21 Batch  100/2536 - Train Accuracy: 0.7528, Validation Accuracy: 0.6339, Loss: 1.2691\n",
      "Epoch  21 Batch  200/2536 - Train Accuracy: 0.7634, Validation Accuracy: 0.6339, Loss: 1.1807\n",
      "Epoch  21 Batch  300/2536 - Train Accuracy: 0.7857, Validation Accuracy: 0.6339, Loss: 1.0366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  21 Batch  400/2536 - Train Accuracy: 0.7168, Validation Accuracy: 0.6339, Loss: 1.4231\n",
      "Epoch  21 Batch  500/2536 - Train Accuracy: 0.6417, Validation Accuracy: 0.6339, Loss: 1.7804\n",
      "Epoch  21 Batch  600/2536 - Train Accuracy: 0.6604, Validation Accuracy: 0.6339, Loss: 1.6989\n",
      "Epoch  21 Batch  700/2536 - Train Accuracy: 0.6587, Validation Accuracy: 0.6339, Loss: 1.7454\n",
      "Epoch  21 Batch  800/2536 - Train Accuracy: 0.6250, Validation Accuracy: 0.6339, Loss: 1.8436\n",
      "Epoch  21 Batch  900/2536 - Train Accuracy: 0.5737, Validation Accuracy: 0.6339, Loss: 1.9262\n",
      "Epoch  21 Batch 1000/2536 - Train Accuracy: 0.6208, Validation Accuracy: 0.6339, Loss: 1.7957\n",
      "Epoch  21 Batch 1100/2536 - Train Accuracy: 0.4621, Validation Accuracy: 0.6339, Loss: 2.4932\n",
      "Epoch  21 Batch 1200/2536 - Train Accuracy: 0.5586, Validation Accuracy: 0.6339, Loss: 1.7691\n",
      "Epoch  21 Batch 1300/2536 - Train Accuracy: 0.8197, Validation Accuracy: 0.6339, Loss: 0.7611\n",
      "Epoch  21 Batch 1400/2536 - Train Accuracy: 0.5875, Validation Accuracy: 0.6339, Loss: 1.9945\n",
      "Epoch  21 Batch 1500/2536 - Train Accuracy: 0.7019, Validation Accuracy: 0.6339, Loss: 1.2698\n",
      "Epoch  21 Batch 1600/2536 - Train Accuracy: 0.6719, Validation Accuracy: 0.6339, Loss: 1.5813\n",
      "Epoch  21 Batch 1700/2536 - Train Accuracy: 0.7670, Validation Accuracy: 0.6339, Loss: 1.2260\n",
      "Epoch  21 Batch 1800/2536 - Train Accuracy: 0.8125, Validation Accuracy: 0.6339, Loss: 0.9192\n",
      "Epoch  21 Batch 1900/2536 - Train Accuracy: 0.6875, Validation Accuracy: 0.6339, Loss: 1.4062\n",
      "Epoch  21 Batch 2000/2536 - Train Accuracy: 0.6562, Validation Accuracy: 0.6339, Loss: 1.4963\n",
      "Epoch  21 Batch 2100/2536 - Train Accuracy: 0.6849, Validation Accuracy: 0.6339, Loss: 1.0012\n",
      "Epoch  21 Batch 2200/2536 - Train Accuracy: 0.6917, Validation Accuracy: 0.6339, Loss: 1.5061\n",
      "Epoch  21 Batch 2300/2536 - Train Accuracy: 0.4471, Validation Accuracy: 0.6339, Loss: 2.6364\n",
      "Epoch  21 Batch 2400/2536 - Train Accuracy: 0.6154, Validation Accuracy: 0.6339, Loss: 1.9108\n",
      "Epoch  21 Batch 2500/2536 - Train Accuracy: 0.5096, Validation Accuracy: 0.6339, Loss: 2.4070\n",
      "Epoch  22 Batch  100/2536 - Train Accuracy: 0.7500, Validation Accuracy: 0.6339, Loss: 1.2016\n",
      "Epoch  22 Batch  200/2536 - Train Accuracy: 0.7656, Validation Accuracy: 0.6339, Loss: 1.1425\n",
      "Epoch  22 Batch  300/2536 - Train Accuracy: 0.7835, Validation Accuracy: 0.6339, Loss: 0.9796\n",
      "Epoch  22 Batch  400/2536 - Train Accuracy: 0.6953, Validation Accuracy: 0.6339, Loss: 1.3765\n",
      "Epoch  22 Batch  500/2536 - Train Accuracy: 0.6375, Validation Accuracy: 0.6339, Loss: 1.7365\n",
      "Epoch  22 Batch  600/2536 - Train Accuracy: 0.6604, Validation Accuracy: 0.6339, Loss: 1.6530\n",
      "Epoch  22 Batch  700/2536 - Train Accuracy: 0.6611, Validation Accuracy: 0.6339, Loss: 1.7007\n",
      "Epoch  22 Batch  800/2536 - Train Accuracy: 0.6322, Validation Accuracy: 0.6339, Loss: 1.8119\n",
      "Epoch  22 Batch  900/2536 - Train Accuracy: 0.5871, Validation Accuracy: 0.6339, Loss: 1.8702\n",
      "Epoch  22 Batch 1000/2536 - Train Accuracy: 0.5958, Validation Accuracy: 0.6339, Loss: 1.7692\n",
      "Epoch  22 Batch 1100/2536 - Train Accuracy: 0.4554, Validation Accuracy: 0.6339, Loss: 2.4259\n",
      "Epoch  22 Batch 1200/2536 - Train Accuracy: 0.5820, Validation Accuracy: 0.6339, Loss: 1.7135\n",
      "Epoch  22 Batch 1300/2536 - Train Accuracy: 0.8389, Validation Accuracy: 0.6339, Loss: 0.7026\n",
      "Epoch  22 Batch 1400/2536 - Train Accuracy: 0.5917, Validation Accuracy: 0.6339, Loss: 1.9486\n",
      "Epoch  22 Batch 1500/2536 - Train Accuracy: 0.7188, Validation Accuracy: 0.6339, Loss: 1.2185\n",
      "Epoch  22 Batch 1600/2536 - Train Accuracy: 0.6745, Validation Accuracy: 0.6339, Loss: 1.5129\n",
      "Epoch  22 Batch 1700/2536 - Train Accuracy: 0.7812, Validation Accuracy: 0.6339, Loss: 1.1831\n",
      "Epoch  22 Batch 1800/2536 - Train Accuracy: 0.8295, Validation Accuracy: 0.6339, Loss: 0.8769\n",
      "Epoch  22 Batch 1900/2536 - Train Accuracy: 0.7083, Validation Accuracy: 0.6339, Loss: 1.3585\n",
      "Epoch  22 Batch 2000/2536 - Train Accuracy: 0.6611, Validation Accuracy: 0.6339, Loss: 1.4560\n",
      "Epoch  22 Batch 2100/2536 - Train Accuracy: 0.7031, Validation Accuracy: 0.6339, Loss: 0.9375\n",
      "Epoch  22 Batch 2200/2536 - Train Accuracy: 0.6937, Validation Accuracy: 0.6339, Loss: 1.4605\n",
      "Epoch  22 Batch 2300/2536 - Train Accuracy: 0.4639, Validation Accuracy: 0.6339, Loss: 2.5675\n",
      "Epoch  22 Batch 2400/2536 - Train Accuracy: 0.6418, Validation Accuracy: 0.6339, Loss: 1.8392\n",
      "Epoch  22 Batch 2500/2536 - Train Accuracy: 0.5240, Validation Accuracy: 0.6339, Loss: 2.3245\n",
      "Epoch  23 Batch  100/2536 - Train Accuracy: 0.7642, Validation Accuracy: 0.6339, Loss: 1.1381\n",
      "Epoch  23 Batch  200/2536 - Train Accuracy: 0.7701, Validation Accuracy: 0.6339, Loss: 1.1122\n",
      "Epoch  23 Batch  300/2536 - Train Accuracy: 0.7812, Validation Accuracy: 0.6339, Loss: 0.9617\n",
      "Epoch  23 Batch  400/2536 - Train Accuracy: 0.7051, Validation Accuracy: 0.6339, Loss: 1.3177\n",
      "Epoch  23 Batch  500/2536 - Train Accuracy: 0.6458, Validation Accuracy: 0.6339, Loss: 1.6724\n",
      "Epoch  23 Batch  600/2536 - Train Accuracy: 0.6562, Validation Accuracy: 0.6339, Loss: 1.5952\n",
      "Epoch  23 Batch  700/2536 - Train Accuracy: 0.6755, Validation Accuracy: 0.6339, Loss: 1.6531\n",
      "Epoch  23 Batch  800/2536 - Train Accuracy: 0.6466, Validation Accuracy: 0.6339, Loss: 1.7507\n",
      "Epoch  23 Batch  900/2536 - Train Accuracy: 0.5759, Validation Accuracy: 0.6339, Loss: 1.8284\n",
      "Epoch  23 Batch 1000/2536 - Train Accuracy: 0.5896, Validation Accuracy: 0.6339, Loss: 1.7192\n",
      "Epoch  23 Batch 1100/2536 - Train Accuracy: 0.4531, Validation Accuracy: 0.6339, Loss: 2.3528\n",
      "Epoch  23 Batch 1200/2536 - Train Accuracy: 0.5820, Validation Accuracy: 0.6339, Loss: 1.6697\n",
      "Epoch  23 Batch 1300/2536 - Train Accuracy: 0.8293, Validation Accuracy: 0.6339, Loss: 0.6526\n",
      "Epoch  23 Batch 1400/2536 - Train Accuracy: 0.5917, Validation Accuracy: 0.6339, Loss: 1.8769\n",
      "Epoch  23 Batch 1500/2536 - Train Accuracy: 0.7404, Validation Accuracy: 0.6339, Loss: 1.1973\n",
      "Epoch  23 Batch 1600/2536 - Train Accuracy: 0.6667, Validation Accuracy: 0.6339, Loss: 1.4738\n",
      "Epoch  23 Batch 1700/2536 - Train Accuracy: 0.7756, Validation Accuracy: 0.6339, Loss: 1.1374\n",
      "Epoch  23 Batch 1800/2536 - Train Accuracy: 0.8295, Validation Accuracy: 0.6339, Loss: 0.8373\n",
      "Epoch  23 Batch 1900/2536 - Train Accuracy: 0.6953, Validation Accuracy: 0.6339, Loss: 1.3108\n",
      "Epoch  23 Batch 2000/2536 - Train Accuracy: 0.6779, Validation Accuracy: 0.6339, Loss: 1.3902\n",
      "Epoch  23 Batch 2100/2536 - Train Accuracy: 0.7500, Validation Accuracy: 0.6339, Loss: 0.8331\n",
      "Epoch  23 Batch 2200/2536 - Train Accuracy: 0.6875, Validation Accuracy: 0.6339, Loss: 1.4216\n",
      "Epoch  23 Batch 2300/2536 - Train Accuracy: 0.4639, Validation Accuracy: 0.6339, Loss: 2.4912\n",
      "Epoch  23 Batch 2400/2536 - Train Accuracy: 0.6370, Validation Accuracy: 0.6339, Loss: 1.7904\n",
      "Epoch  23 Batch 2500/2536 - Train Accuracy: 0.5120, Validation Accuracy: 0.6339, Loss: 2.2616\n",
      "Epoch  24 Batch  100/2536 - Train Accuracy: 0.7784, Validation Accuracy: 0.6339, Loss: 1.0995\n",
      "Epoch  24 Batch  200/2536 - Train Accuracy: 0.7879, Validation Accuracy: 0.6339, Loss: 1.0694\n",
      "Epoch  24 Batch  300/2536 - Train Accuracy: 0.7835, Validation Accuracy: 0.6339, Loss: 0.9290\n",
      "Epoch  24 Batch  400/2536 - Train Accuracy: 0.7188, Validation Accuracy: 0.6339, Loss: 1.2878\n",
      "Epoch  24 Batch  500/2536 - Train Accuracy: 0.6292, Validation Accuracy: 0.6339, Loss: 1.6378\n",
      "Epoch  24 Batch  600/2536 - Train Accuracy: 0.6813, Validation Accuracy: 0.6339, Loss: 1.5568\n",
      "Epoch  24 Batch  700/2536 - Train Accuracy: 0.6562, Validation Accuracy: 0.6339, Loss: 1.6062\n",
      "Epoch  24 Batch  800/2536 - Train Accuracy: 0.6490, Validation Accuracy: 0.6339, Loss: 1.7139\n",
      "Epoch  24 Batch  900/2536 - Train Accuracy: 0.5670, Validation Accuracy: 0.6339, Loss: 1.7791\n",
      "Epoch  24 Batch 1000/2536 - Train Accuracy: 0.6333, Validation Accuracy: 0.6339, Loss: 1.6965\n",
      "Epoch  24 Batch 1100/2536 - Train Accuracy: 0.4598, Validation Accuracy: 0.6339, Loss: 2.2972\n",
      "Epoch  24 Batch 1200/2536 - Train Accuracy: 0.5898, Validation Accuracy: 0.6339, Loss: 1.6189\n",
      "Epoch  24 Batch 1300/2536 - Train Accuracy: 0.8413, Validation Accuracy: 0.6339, Loss: 0.6108\n",
      "Epoch  24 Batch 1400/2536 - Train Accuracy: 0.5979, Validation Accuracy: 0.6339, Loss: 1.8225\n",
      "Epoch  24 Batch 1500/2536 - Train Accuracy: 0.7163, Validation Accuracy: 0.6339, Loss: 1.1457\n",
      "Epoch  24 Batch 1600/2536 - Train Accuracy: 0.6719, Validation Accuracy: 0.6339, Loss: 1.4363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  24 Batch 1700/2536 - Train Accuracy: 0.7670, Validation Accuracy: 0.6339, Loss: 1.1031\n",
      "Epoch  24 Batch 1800/2536 - Train Accuracy: 0.8324, Validation Accuracy: 0.6339, Loss: 0.8156\n",
      "Epoch  24 Batch 1900/2536 - Train Accuracy: 0.6979, Validation Accuracy: 0.6339, Loss: 1.2803\n",
      "Epoch  24 Batch 2000/2536 - Train Accuracy: 0.6707, Validation Accuracy: 0.6339, Loss: 1.3598\n",
      "Epoch  24 Batch 2100/2536 - Train Accuracy: 0.7500, Validation Accuracy: 0.6339, Loss: 0.7617\n",
      "Epoch  24 Batch 2200/2536 - Train Accuracy: 0.7167, Validation Accuracy: 0.6339, Loss: 1.3838\n",
      "Epoch  24 Batch 2300/2536 - Train Accuracy: 0.4856, Validation Accuracy: 0.6339, Loss: 2.4284\n",
      "Epoch  24 Batch 2400/2536 - Train Accuracy: 0.6298, Validation Accuracy: 0.6339, Loss: 1.7417\n",
      "Epoch  24 Batch 2500/2536 - Train Accuracy: 0.5457, Validation Accuracy: 0.6339, Loss: 2.1797\n",
      "Epoch  25 Batch  100/2536 - Train Accuracy: 0.7784, Validation Accuracy: 0.6339, Loss: 1.0521\n",
      "Epoch  25 Batch  200/2536 - Train Accuracy: 0.7746, Validation Accuracy: 0.6339, Loss: 1.0459\n",
      "Epoch  25 Batch  300/2536 - Train Accuracy: 0.7790, Validation Accuracy: 0.6339, Loss: 0.9095\n",
      "Epoch  25 Batch  400/2536 - Train Accuracy: 0.7207, Validation Accuracy: 0.6339, Loss: 1.2520\n",
      "Epoch  25 Batch  500/2536 - Train Accuracy: 0.6646, Validation Accuracy: 0.6339, Loss: 1.6094\n",
      "Epoch  25 Batch  600/2536 - Train Accuracy: 0.6729, Validation Accuracy: 0.6339, Loss: 1.4913\n",
      "Epoch  25 Batch  700/2536 - Train Accuracy: 0.6731, Validation Accuracy: 0.6339, Loss: 1.5463\n",
      "Epoch  25 Batch  800/2536 - Train Accuracy: 0.6683, Validation Accuracy: 0.6339, Loss: 1.6435\n",
      "Epoch  25 Batch  900/2536 - Train Accuracy: 0.5625, Validation Accuracy: 0.6339, Loss: 1.7355\n",
      "Epoch  25 Batch 1000/2536 - Train Accuracy: 0.6312, Validation Accuracy: 0.6339, Loss: 1.6247\n",
      "Epoch  25 Batch 1100/2536 - Train Accuracy: 0.4844, Validation Accuracy: 0.6339, Loss: 2.2531\n",
      "Epoch  25 Batch 1200/2536 - Train Accuracy: 0.6172, Validation Accuracy: 0.6339, Loss: 1.5662\n",
      "Epoch  25 Batch 1300/2536 - Train Accuracy: 0.8582, Validation Accuracy: 0.6339, Loss: 0.5600\n",
      "Epoch  25 Batch 1400/2536 - Train Accuracy: 0.5958, Validation Accuracy: 0.6339, Loss: 1.7758\n",
      "Epoch  25 Batch 1500/2536 - Train Accuracy: 0.7380, Validation Accuracy: 0.6339, Loss: 1.0995\n",
      "Epoch  25 Batch 1600/2536 - Train Accuracy: 0.6901, Validation Accuracy: 0.6339, Loss: 1.3808\n",
      "Epoch  25 Batch 1700/2536 - Train Accuracy: 0.7869, Validation Accuracy: 0.6339, Loss: 1.0626\n",
      "Epoch  25 Batch 1800/2536 - Train Accuracy: 0.8182, Validation Accuracy: 0.6339, Loss: 0.7822\n",
      "Epoch  25 Batch 1900/2536 - Train Accuracy: 0.7422, Validation Accuracy: 0.6339, Loss: 1.2252\n",
      "Epoch  25 Batch 2000/2536 - Train Accuracy: 0.6971, Validation Accuracy: 0.6339, Loss: 1.3182\n",
      "Epoch  25 Batch 2100/2536 - Train Accuracy: 0.7917, Validation Accuracy: 0.6339, Loss: 0.7140\n",
      "Epoch  25 Batch 2200/2536 - Train Accuracy: 0.6958, Validation Accuracy: 0.6339, Loss: 1.3466\n",
      "Epoch  25 Batch 2300/2536 - Train Accuracy: 0.4904, Validation Accuracy: 0.6339, Loss: 2.3760\n",
      "Epoch  25 Batch 2400/2536 - Train Accuracy: 0.6298, Validation Accuracy: 0.6339, Loss: 1.6919\n",
      "Epoch  25 Batch 2500/2536 - Train Accuracy: 0.5192, Validation Accuracy: 0.6339, Loss: 2.1418\n",
      "Epoch  26 Batch  100/2536 - Train Accuracy: 0.7756, Validation Accuracy: 0.6339, Loss: 1.0152\n",
      "Epoch  26 Batch  200/2536 - Train Accuracy: 0.7857, Validation Accuracy: 0.6339, Loss: 1.0158\n",
      "Epoch  26 Batch  300/2536 - Train Accuracy: 0.7924, Validation Accuracy: 0.6339, Loss: 0.8703\n",
      "Epoch  26 Batch  400/2536 - Train Accuracy: 0.7090, Validation Accuracy: 0.6339, Loss: 1.2195\n",
      "Epoch  26 Batch  500/2536 - Train Accuracy: 0.6625, Validation Accuracy: 0.6339, Loss: 1.5554\n",
      "Epoch  26 Batch  600/2536 - Train Accuracy: 0.6958, Validation Accuracy: 0.6339, Loss: 1.4626\n",
      "Epoch  26 Batch  700/2536 - Train Accuracy: 0.6899, Validation Accuracy: 0.6339, Loss: 1.5040\n",
      "Epoch  26 Batch  800/2536 - Train Accuracy: 0.6635, Validation Accuracy: 0.6339, Loss: 1.6178\n",
      "Epoch  26 Batch  900/2536 - Train Accuracy: 0.6027, Validation Accuracy: 0.6339, Loss: 1.6521\n",
      "Epoch  26 Batch 1000/2536 - Train Accuracy: 0.6438, Validation Accuracy: 0.6339, Loss: 1.5641\n",
      "Epoch  26 Batch 1100/2536 - Train Accuracy: 0.4777, Validation Accuracy: 0.6339, Loss: 2.1925\n",
      "Epoch  26 Batch 1200/2536 - Train Accuracy: 0.5801, Validation Accuracy: 0.6339, Loss: 1.5430\n",
      "Epoch  26 Batch 1300/2536 - Train Accuracy: 0.8654, Validation Accuracy: 0.6339, Loss: 0.5177\n",
      "Epoch  26 Batch 1400/2536 - Train Accuracy: 0.6042, Validation Accuracy: 0.6339, Loss: 1.7443\n",
      "Epoch  26 Batch 1500/2536 - Train Accuracy: 0.7668, Validation Accuracy: 0.6339, Loss: 1.0694\n",
      "Epoch  26 Batch 1600/2536 - Train Accuracy: 0.6849, Validation Accuracy: 0.6339, Loss: 1.3487\n",
      "Epoch  26 Batch 1700/2536 - Train Accuracy: 0.7869, Validation Accuracy: 0.6339, Loss: 1.0155\n",
      "Epoch  26 Batch 1800/2536 - Train Accuracy: 0.8409, Validation Accuracy: 0.6339, Loss: 0.7609\n",
      "Epoch  26 Batch 1900/2536 - Train Accuracy: 0.7266, Validation Accuracy: 0.6339, Loss: 1.1901\n",
      "Epoch  26 Batch 2000/2536 - Train Accuracy: 0.6995, Validation Accuracy: 0.6339, Loss: 1.2775\n",
      "Epoch  26 Batch 2100/2536 - Train Accuracy: 0.7917, Validation Accuracy: 0.6339, Loss: 0.6358\n",
      "Epoch  26 Batch 2200/2536 - Train Accuracy: 0.7063, Validation Accuracy: 0.6339, Loss: 1.2980\n",
      "Epoch  26 Batch 2300/2536 - Train Accuracy: 0.4952, Validation Accuracy: 0.6339, Loss: 2.3110\n",
      "Epoch  26 Batch 2400/2536 - Train Accuracy: 0.6394, Validation Accuracy: 0.6339, Loss: 1.6372\n",
      "Epoch  26 Batch 2500/2536 - Train Accuracy: 0.5433, Validation Accuracy: 0.6339, Loss: 2.1001\n",
      "Epoch  27 Batch  100/2536 - Train Accuracy: 0.7926, Validation Accuracy: 0.6339, Loss: 0.9754\n",
      "Epoch  27 Batch  200/2536 - Train Accuracy: 0.7790, Validation Accuracy: 0.6339, Loss: 0.9891\n",
      "Epoch  27 Batch  300/2536 - Train Accuracy: 0.7902, Validation Accuracy: 0.6339, Loss: 0.8515\n",
      "Epoch  27 Batch  400/2536 - Train Accuracy: 0.7363, Validation Accuracy: 0.6339, Loss: 1.1680\n",
      "Epoch  27 Batch  500/2536 - Train Accuracy: 0.6542, Validation Accuracy: 0.6339, Loss: 1.5024\n",
      "Epoch  27 Batch  600/2536 - Train Accuracy: 0.6854, Validation Accuracy: 0.6339, Loss: 1.4060\n",
      "Epoch  27 Batch  700/2536 - Train Accuracy: 0.6755, Validation Accuracy: 0.6339, Loss: 1.4813\n",
      "Epoch  27 Batch  800/2536 - Train Accuracy: 0.6611, Validation Accuracy: 0.6339, Loss: 1.5640\n",
      "Epoch  27 Batch  900/2536 - Train Accuracy: 0.5960, Validation Accuracy: 0.6339, Loss: 1.6357\n",
      "Epoch  27 Batch 1000/2536 - Train Accuracy: 0.6104, Validation Accuracy: 0.6339, Loss: 1.5348\n",
      "Epoch  27 Batch 1100/2536 - Train Accuracy: 0.5067, Validation Accuracy: 0.6339, Loss: 2.1278\n",
      "Epoch  27 Batch 1200/2536 - Train Accuracy: 0.5977, Validation Accuracy: 0.6339, Loss: 1.4837\n",
      "Epoch  27 Batch 1300/2536 - Train Accuracy: 0.8822, Validation Accuracy: 0.6339, Loss: 0.4830\n",
      "Epoch  27 Batch 1400/2536 - Train Accuracy: 0.6000, Validation Accuracy: 0.6339, Loss: 1.6926\n",
      "Epoch  27 Batch 1500/2536 - Train Accuracy: 0.7692, Validation Accuracy: 0.6339, Loss: 1.0264\n",
      "Epoch  27 Batch 1600/2536 - Train Accuracy: 0.6875, Validation Accuracy: 0.6339, Loss: 1.2846\n",
      "Epoch  27 Batch 1700/2536 - Train Accuracy: 0.7926, Validation Accuracy: 0.6339, Loss: 0.9955\n",
      "Epoch  27 Batch 1800/2536 - Train Accuracy: 0.8494, Validation Accuracy: 0.6339, Loss: 0.7179\n",
      "Epoch  27 Batch 1900/2536 - Train Accuracy: 0.7370, Validation Accuracy: 0.6339, Loss: 1.1491\n",
      "Epoch  27 Batch 2000/2536 - Train Accuracy: 0.6923, Validation Accuracy: 0.6339, Loss: 1.2415\n",
      "Epoch  27 Batch 2100/2536 - Train Accuracy: 0.8125, Validation Accuracy: 0.6339, Loss: 0.5793\n",
      "Epoch  27 Batch 2200/2536 - Train Accuracy: 0.7042, Validation Accuracy: 0.6339, Loss: 1.2456\n",
      "Epoch  27 Batch 2300/2536 - Train Accuracy: 0.5288, Validation Accuracy: 0.6339, Loss: 2.2399\n",
      "Epoch  27 Batch 2400/2536 - Train Accuracy: 0.6274, Validation Accuracy: 0.6339, Loss: 1.5857\n",
      "Epoch  27 Batch 2500/2536 - Train Accuracy: 0.5433, Validation Accuracy: 0.6339, Loss: 2.0264\n",
      "Epoch  28 Batch  100/2536 - Train Accuracy: 0.7955, Validation Accuracy: 0.6339, Loss: 0.9222\n",
      "Epoch  28 Batch  200/2536 - Train Accuracy: 0.7812, Validation Accuracy: 0.6339, Loss: 0.9606\n",
      "Epoch  28 Batch  300/2536 - Train Accuracy: 0.7902, Validation Accuracy: 0.6339, Loss: 0.8173\n",
      "Epoch  28 Batch  400/2536 - Train Accuracy: 0.7461, Validation Accuracy: 0.6339, Loss: 1.1408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  28 Batch  500/2536 - Train Accuracy: 0.6500, Validation Accuracy: 0.6339, Loss: 1.4608\n",
      "Epoch  28 Batch  600/2536 - Train Accuracy: 0.6667, Validation Accuracy: 0.6339, Loss: 1.3757\n",
      "Epoch  28 Batch  700/2536 - Train Accuracy: 0.6947, Validation Accuracy: 0.6339, Loss: 1.4225\n",
      "Epoch  28 Batch  800/2536 - Train Accuracy: 0.6755, Validation Accuracy: 0.6339, Loss: 1.5307\n",
      "Epoch  28 Batch  900/2536 - Train Accuracy: 0.6161, Validation Accuracy: 0.6339, Loss: 1.5863\n",
      "Epoch  28 Batch 1000/2536 - Train Accuracy: 0.6312, Validation Accuracy: 0.6339, Loss: 1.5031\n",
      "Epoch  28 Batch 1100/2536 - Train Accuracy: 0.5268, Validation Accuracy: 0.6339, Loss: 2.0889\n",
      "Epoch  28 Batch 1200/2536 - Train Accuracy: 0.6035, Validation Accuracy: 0.6339, Loss: 1.4482\n",
      "Epoch  28 Batch 1300/2536 - Train Accuracy: 0.8966, Validation Accuracy: 0.6339, Loss: 0.4484\n",
      "Epoch  28 Batch 1400/2536 - Train Accuracy: 0.6146, Validation Accuracy: 0.6339, Loss: 1.6501\n",
      "Epoch  28 Batch 1500/2536 - Train Accuracy: 0.7404, Validation Accuracy: 0.6339, Loss: 0.9912\n",
      "Epoch  28 Batch 1600/2536 - Train Accuracy: 0.7188, Validation Accuracy: 0.6339, Loss: 1.2517\n",
      "Epoch  28 Batch 1700/2536 - Train Accuracy: 0.7784, Validation Accuracy: 0.6339, Loss: 0.9521\n",
      "Epoch  28 Batch 1800/2536 - Train Accuracy: 0.8267, Validation Accuracy: 0.6339, Loss: 0.6981\n",
      "Epoch  28 Batch 1900/2536 - Train Accuracy: 0.7526, Validation Accuracy: 0.6339, Loss: 1.1081\n",
      "Epoch  28 Batch 2000/2536 - Train Accuracy: 0.6803, Validation Accuracy: 0.6339, Loss: 1.2034\n",
      "Epoch  28 Batch 2100/2536 - Train Accuracy: 0.8099, Validation Accuracy: 0.6339, Loss: 0.5217\n",
      "Epoch  28 Batch 2200/2536 - Train Accuracy: 0.7312, Validation Accuracy: 0.6339, Loss: 1.2179\n",
      "Epoch  28 Batch 2300/2536 - Train Accuracy: 0.5312, Validation Accuracy: 0.6339, Loss: 2.1688\n",
      "Epoch  28 Batch 2400/2536 - Train Accuracy: 0.6514, Validation Accuracy: 0.6339, Loss: 1.5262\n",
      "Epoch  28 Batch 2500/2536 - Train Accuracy: 0.5216, Validation Accuracy: 0.6339, Loss: 1.9964\n",
      "Epoch  29 Batch  100/2536 - Train Accuracy: 0.7812, Validation Accuracy: 0.6339, Loss: 0.8940\n",
      "Epoch  29 Batch  200/2536 - Train Accuracy: 0.7969, Validation Accuracy: 0.6339, Loss: 0.9244\n",
      "Epoch  29 Batch  300/2536 - Train Accuracy: 0.8103, Validation Accuracy: 0.6339, Loss: 0.7734\n",
      "Epoch  29 Batch  400/2536 - Train Accuracy: 0.7441, Validation Accuracy: 0.6339, Loss: 1.1158\n",
      "Epoch  29 Batch  500/2536 - Train Accuracy: 0.6646, Validation Accuracy: 0.6339, Loss: 1.4193\n",
      "Epoch  29 Batch  600/2536 - Train Accuracy: 0.6813, Validation Accuracy: 0.6339, Loss: 1.3566\n",
      "Epoch  29 Batch  700/2536 - Train Accuracy: 0.7043, Validation Accuracy: 0.6339, Loss: 1.3728\n",
      "Epoch  29 Batch  800/2536 - Train Accuracy: 0.6947, Validation Accuracy: 0.6339, Loss: 1.4837\n",
      "Epoch  29 Batch  900/2536 - Train Accuracy: 0.6027, Validation Accuracy: 0.6339, Loss: 1.5578\n",
      "Epoch  29 Batch 1000/2536 - Train Accuracy: 0.6458, Validation Accuracy: 0.6339, Loss: 1.4615\n",
      "Epoch  29 Batch 1100/2536 - Train Accuracy: 0.4777, Validation Accuracy: 0.6339, Loss: 2.0474\n",
      "Epoch  29 Batch 1200/2536 - Train Accuracy: 0.6133, Validation Accuracy: 0.6339, Loss: 1.4026\n",
      "Epoch  29 Batch 1300/2536 - Train Accuracy: 0.8774, Validation Accuracy: 0.6339, Loss: 0.4127\n",
      "Epoch  29 Batch 1400/2536 - Train Accuracy: 0.6021, Validation Accuracy: 0.6339, Loss: 1.6203\n",
      "Epoch  29 Batch 1500/2536 - Train Accuracy: 0.7476, Validation Accuracy: 0.6339, Loss: 0.9527\n",
      "Epoch  29 Batch 1600/2536 - Train Accuracy: 0.7214, Validation Accuracy: 0.6339, Loss: 1.2081\n",
      "Epoch  29 Batch 1700/2536 - Train Accuracy: 0.8011, Validation Accuracy: 0.6339, Loss: 0.9321\n",
      "Epoch  29 Batch 1800/2536 - Train Accuracy: 0.8665, Validation Accuracy: 0.6339, Loss: 0.6611\n",
      "Epoch  29 Batch 1900/2536 - Train Accuracy: 0.7500, Validation Accuracy: 0.6339, Loss: 1.0693\n",
      "Epoch  29 Batch 2000/2536 - Train Accuracy: 0.6851, Validation Accuracy: 0.6339, Loss: 1.1705\n",
      "Epoch  29 Batch 2100/2536 - Train Accuracy: 0.8255, Validation Accuracy: 0.6339, Loss: 0.5017\n",
      "Epoch  29 Batch 2200/2536 - Train Accuracy: 0.6958, Validation Accuracy: 0.6339, Loss: 1.1899\n",
      "Epoch  29 Batch 2300/2536 - Train Accuracy: 0.5144, Validation Accuracy: 0.6339, Loss: 2.1195\n",
      "Epoch  29 Batch 2400/2536 - Train Accuracy: 0.6346, Validation Accuracy: 0.6339, Loss: 1.4922\n",
      "Epoch  29 Batch 2500/2536 - Train Accuracy: 0.5529, Validation Accuracy: 0.6339, Loss: 1.9399\n",
      "Epoch  30 Batch  100/2536 - Train Accuracy: 0.8040, Validation Accuracy: 0.6339, Loss: 0.8543\n",
      "Epoch  30 Batch  200/2536 - Train Accuracy: 0.7991, Validation Accuracy: 0.6339, Loss: 0.9043\n",
      "Epoch  30 Batch  300/2536 - Train Accuracy: 0.8237, Validation Accuracy: 0.6339, Loss: 0.7559\n",
      "Epoch  30 Batch  400/2536 - Train Accuracy: 0.7402, Validation Accuracy: 0.6339, Loss: 1.0782\n",
      "Epoch  30 Batch  500/2536 - Train Accuracy: 0.7000, Validation Accuracy: 0.6339, Loss: 1.3771\n",
      "Epoch  30 Batch  600/2536 - Train Accuracy: 0.6708, Validation Accuracy: 0.6339, Loss: 1.3044\n",
      "Epoch  30 Batch  700/2536 - Train Accuracy: 0.6947, Validation Accuracy: 0.6339, Loss: 1.3485\n",
      "Epoch  30 Batch  800/2536 - Train Accuracy: 0.6971, Validation Accuracy: 0.6339, Loss: 1.4409\n",
      "Epoch  30 Batch  900/2536 - Train Accuracy: 0.6473, Validation Accuracy: 0.6339, Loss: 1.5052\n",
      "Epoch  30 Batch 1000/2536 - Train Accuracy: 0.6354, Validation Accuracy: 0.6339, Loss: 1.4347\n",
      "Epoch  30 Batch 1100/2536 - Train Accuracy: 0.5022, Validation Accuracy: 0.6339, Loss: 1.9864\n",
      "Epoch  30 Batch 1200/2536 - Train Accuracy: 0.6250, Validation Accuracy: 0.6339, Loss: 1.3570\n",
      "Epoch  30 Batch 1300/2536 - Train Accuracy: 0.8774, Validation Accuracy: 0.6339, Loss: 0.3887\n",
      "Epoch  30 Batch 1400/2536 - Train Accuracy: 0.6417, Validation Accuracy: 0.6339, Loss: 1.5562\n",
      "Epoch  30 Batch 1500/2536 - Train Accuracy: 0.7740, Validation Accuracy: 0.6339, Loss: 0.9223\n",
      "Epoch  30 Batch 1600/2536 - Train Accuracy: 0.7109, Validation Accuracy: 0.6339, Loss: 1.1686\n",
      "Epoch  30 Batch 1700/2536 - Train Accuracy: 0.7983, Validation Accuracy: 0.6339, Loss: 0.8872\n",
      "Epoch  30 Batch 1800/2536 - Train Accuracy: 0.8466, Validation Accuracy: 0.6339, Loss: 0.6282\n",
      "Epoch  30 Batch 1900/2536 - Train Accuracy: 0.7578, Validation Accuracy: 0.6339, Loss: 1.0524\n",
      "Epoch  30 Batch 2000/2536 - Train Accuracy: 0.6851, Validation Accuracy: 0.6339, Loss: 1.1157\n",
      "Epoch  30 Batch 2100/2536 - Train Accuracy: 0.8490, Validation Accuracy: 0.6339, Loss: 0.4477\n",
      "Epoch  30 Batch 2200/2536 - Train Accuracy: 0.7167, Validation Accuracy: 0.6339, Loss: 1.1448\n",
      "Epoch  30 Batch 2300/2536 - Train Accuracy: 0.5433, Validation Accuracy: 0.6339, Loss: 2.0703\n",
      "Epoch  30 Batch 2400/2536 - Train Accuracy: 0.6635, Validation Accuracy: 0.6339, Loss: 1.4533\n",
      "Epoch  30 Batch 2500/2536 - Train Accuracy: 0.5577, Validation Accuracy: 0.6339, Loss: 1.8972\n",
      "Epoch  31 Batch  100/2536 - Train Accuracy: 0.8295, Validation Accuracy: 0.6339, Loss: 0.8086\n",
      "Epoch  31 Batch  200/2536 - Train Accuracy: 0.7946, Validation Accuracy: 0.6339, Loss: 0.8764\n",
      "Epoch  31 Batch  300/2536 - Train Accuracy: 0.8125, Validation Accuracy: 0.6339, Loss: 0.7328\n",
      "Epoch  31 Batch  400/2536 - Train Accuracy: 0.7480, Validation Accuracy: 0.6339, Loss: 1.0544\n",
      "Epoch  31 Batch  500/2536 - Train Accuracy: 0.6958, Validation Accuracy: 0.6339, Loss: 1.3466\n",
      "Epoch  31 Batch  600/2536 - Train Accuracy: 0.6979, Validation Accuracy: 0.6339, Loss: 1.2761\n",
      "Epoch  31 Batch  700/2536 - Train Accuracy: 0.7115, Validation Accuracy: 0.6339, Loss: 1.2866\n",
      "Epoch  31 Batch  800/2536 - Train Accuracy: 0.6923, Validation Accuracy: 0.6339, Loss: 1.3925\n",
      "Epoch  31 Batch  900/2536 - Train Accuracy: 0.6295, Validation Accuracy: 0.6339, Loss: 1.4839\n",
      "Epoch  31 Batch 1000/2536 - Train Accuracy: 0.6667, Validation Accuracy: 0.6339, Loss: 1.3848\n",
      "Epoch  31 Batch 1100/2536 - Train Accuracy: 0.5290, Validation Accuracy: 0.6339, Loss: 1.9364\n",
      "Epoch  31 Batch 1200/2536 - Train Accuracy: 0.6328, Validation Accuracy: 0.6339, Loss: 1.3267\n",
      "Epoch  31 Batch 1300/2536 - Train Accuracy: 0.8870, Validation Accuracy: 0.6339, Loss: 0.3645\n",
      "Epoch  31 Batch 1400/2536 - Train Accuracy: 0.6417, Validation Accuracy: 0.6339, Loss: 1.5352\n",
      "Epoch  31 Batch 1500/2536 - Train Accuracy: 0.7861, Validation Accuracy: 0.6339, Loss: 0.8775\n",
      "Epoch  31 Batch 1600/2536 - Train Accuracy: 0.7292, Validation Accuracy: 0.6339, Loss: 1.1398\n",
      "Epoch  31 Batch 1700/2536 - Train Accuracy: 0.7955, Validation Accuracy: 0.6339, Loss: 0.8649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  31 Batch 1800/2536 - Train Accuracy: 0.8580, Validation Accuracy: 0.6339, Loss: 0.6044\n",
      "Epoch  31 Batch 1900/2536 - Train Accuracy: 0.7500, Validation Accuracy: 0.6339, Loss: 1.0021\n",
      "Epoch  31 Batch 2000/2536 - Train Accuracy: 0.7236, Validation Accuracy: 0.6339, Loss: 1.0635\n",
      "Epoch  31 Batch 2100/2536 - Train Accuracy: 0.8359, Validation Accuracy: 0.6339, Loss: 0.4024\n",
      "Epoch  31 Batch 2200/2536 - Train Accuracy: 0.7458, Validation Accuracy: 0.6339, Loss: 1.1253\n",
      "Epoch  31 Batch 2300/2536 - Train Accuracy: 0.5409, Validation Accuracy: 0.6339, Loss: 1.9949\n",
      "Epoch  31 Batch 2400/2536 - Train Accuracy: 0.6538, Validation Accuracy: 0.6339, Loss: 1.4041\n",
      "Epoch  31 Batch 2500/2536 - Train Accuracy: 0.5721, Validation Accuracy: 0.6339, Loss: 1.8452\n",
      "Epoch  32 Batch  100/2536 - Train Accuracy: 0.8125, Validation Accuracy: 0.6339, Loss: 0.7741\n",
      "Epoch  32 Batch  200/2536 - Train Accuracy: 0.7969, Validation Accuracy: 0.6339, Loss: 0.8517\n",
      "Epoch  32 Batch  300/2536 - Train Accuracy: 0.8237, Validation Accuracy: 0.6339, Loss: 0.7161\n",
      "Epoch  32 Batch  400/2536 - Train Accuracy: 0.7480, Validation Accuracy: 0.6339, Loss: 1.0215\n",
      "Epoch  32 Batch  500/2536 - Train Accuracy: 0.7125, Validation Accuracy: 0.6339, Loss: 1.3097\n",
      "Epoch  32 Batch  600/2536 - Train Accuracy: 0.6958, Validation Accuracy: 0.6339, Loss: 1.2396\n",
      "Epoch  32 Batch  700/2536 - Train Accuracy: 0.6899, Validation Accuracy: 0.6339, Loss: 1.2764\n",
      "Epoch  32 Batch  800/2536 - Train Accuracy: 0.6851, Validation Accuracy: 0.6339, Loss: 1.3505\n",
      "Epoch  32 Batch  900/2536 - Train Accuracy: 0.6272, Validation Accuracy: 0.6339, Loss: 1.4408\n",
      "Epoch  32 Batch 1000/2536 - Train Accuracy: 0.6646, Validation Accuracy: 0.6339, Loss: 1.3498\n",
      "Epoch  32 Batch 1100/2536 - Train Accuracy: 0.5402, Validation Accuracy: 0.6339, Loss: 1.8861\n",
      "Epoch  32 Batch 1200/2536 - Train Accuracy: 0.6133, Validation Accuracy: 0.6339, Loss: 1.2809\n",
      "Epoch  32 Batch 1300/2536 - Train Accuracy: 0.9038, Validation Accuracy: 0.6339, Loss: 0.3203\n",
      "Epoch  32 Batch 1400/2536 - Train Accuracy: 0.6417, Validation Accuracy: 0.6339, Loss: 1.4596\n",
      "Epoch  32 Batch 1500/2536 - Train Accuracy: 0.8005, Validation Accuracy: 0.6339, Loss: 0.8375\n",
      "Epoch  32 Batch 1600/2536 - Train Accuracy: 0.7188, Validation Accuracy: 0.6339, Loss: 1.0852\n",
      "Epoch  32 Batch 1700/2536 - Train Accuracy: 0.8040, Validation Accuracy: 0.6339, Loss: 0.8389\n",
      "Epoch  32 Batch 1800/2536 - Train Accuracy: 0.8551, Validation Accuracy: 0.6339, Loss: 0.5898\n",
      "Epoch  32 Batch 1900/2536 - Train Accuracy: 0.7656, Validation Accuracy: 0.6339, Loss: 0.9806\n",
      "Epoch  32 Batch 2000/2536 - Train Accuracy: 0.6851, Validation Accuracy: 0.6339, Loss: 1.0307\n",
      "Epoch  32 Batch 2100/2536 - Train Accuracy: 0.8854, Validation Accuracy: 0.6339, Loss: 0.3801\n",
      "Epoch  32 Batch 2200/2536 - Train Accuracy: 0.7604, Validation Accuracy: 0.6339, Loss: 1.0945\n",
      "Epoch  32 Batch 2300/2536 - Train Accuracy: 0.5577, Validation Accuracy: 0.6339, Loss: 1.9601\n",
      "Epoch  32 Batch 2400/2536 - Train Accuracy: 0.6490, Validation Accuracy: 0.6339, Loss: 1.3727\n",
      "Epoch  32 Batch 2500/2536 - Train Accuracy: 0.5409, Validation Accuracy: 0.6339, Loss: 1.7911\n",
      "Epoch  33 Batch  100/2536 - Train Accuracy: 0.8267, Validation Accuracy: 0.6339, Loss: 0.7412\n",
      "Epoch  33 Batch  200/2536 - Train Accuracy: 0.8103, Validation Accuracy: 0.6339, Loss: 0.8083\n",
      "Epoch  33 Batch  300/2536 - Train Accuracy: 0.8170, Validation Accuracy: 0.6339, Loss: 0.6753\n",
      "Epoch  33 Batch  400/2536 - Train Accuracy: 0.7344, Validation Accuracy: 0.6339, Loss: 0.9714\n",
      "Epoch  33 Batch  500/2536 - Train Accuracy: 0.6958, Validation Accuracy: 0.6362, Loss: 1.2673\n",
      "Epoch  33 Batch  600/2536 - Train Accuracy: 0.7000, Validation Accuracy: 0.6339, Loss: 1.1953\n",
      "Epoch  33 Batch  700/2536 - Train Accuracy: 0.7356, Validation Accuracy: 0.6339, Loss: 1.2179\n",
      "Epoch  33 Batch  800/2536 - Train Accuracy: 0.6851, Validation Accuracy: 0.6339, Loss: 1.3210\n",
      "Epoch  33 Batch  900/2536 - Train Accuracy: 0.6429, Validation Accuracy: 0.6339, Loss: 1.4109\n",
      "Epoch  33 Batch 1000/2536 - Train Accuracy: 0.6583, Validation Accuracy: 0.6339, Loss: 1.3415\n",
      "Epoch  33 Batch 1100/2536 - Train Accuracy: 0.5424, Validation Accuracy: 0.6339, Loss: 1.8414\n",
      "Epoch  33 Batch 1200/2536 - Train Accuracy: 0.6484, Validation Accuracy: 0.6339, Loss: 1.2571\n",
      "Epoch  33 Batch 1300/2536 - Train Accuracy: 0.9183, Validation Accuracy: 0.6339, Loss: 0.3121\n",
      "Epoch  33 Batch 1400/2536 - Train Accuracy: 0.6375, Validation Accuracy: 0.6362, Loss: 1.4332\n",
      "Epoch  33 Batch 1500/2536 - Train Accuracy: 0.8005, Validation Accuracy: 0.6339, Loss: 0.8114\n",
      "Epoch  33 Batch 1600/2536 - Train Accuracy: 0.7656, Validation Accuracy: 0.6339, Loss: 1.0422\n",
      "Epoch  33 Batch 1700/2536 - Train Accuracy: 0.8210, Validation Accuracy: 0.6339, Loss: 0.8094\n",
      "Epoch  33 Batch 1800/2536 - Train Accuracy: 0.8665, Validation Accuracy: 0.6339, Loss: 0.5661\n",
      "Epoch  33 Batch 1900/2536 - Train Accuracy: 0.7682, Validation Accuracy: 0.6339, Loss: 0.9277\n",
      "Epoch  33 Batch 2000/2536 - Train Accuracy: 0.7236, Validation Accuracy: 0.6339, Loss: 0.9767\n",
      "Epoch  33 Batch 2100/2536 - Train Accuracy: 0.8958, Validation Accuracy: 0.6339, Loss: 0.3446\n",
      "Epoch  33 Batch 2200/2536 - Train Accuracy: 0.7562, Validation Accuracy: 0.6339, Loss: 1.0333\n",
      "Epoch  33 Batch 2300/2536 - Train Accuracy: 0.5649, Validation Accuracy: 0.6339, Loss: 1.8988\n",
      "Epoch  33 Batch 2400/2536 - Train Accuracy: 0.6755, Validation Accuracy: 0.6339, Loss: 1.3312\n",
      "Epoch  33 Batch 2500/2536 - Train Accuracy: 0.5817, Validation Accuracy: 0.6339, Loss: 1.7607\n",
      "Epoch  34 Batch  100/2536 - Train Accuracy: 0.8324, Validation Accuracy: 0.6339, Loss: 0.7058\n",
      "Epoch  34 Batch  200/2536 - Train Accuracy: 0.8013, Validation Accuracy: 0.6339, Loss: 0.7865\n",
      "Epoch  34 Batch  300/2536 - Train Accuracy: 0.8438, Validation Accuracy: 0.6339, Loss: 0.6665\n",
      "Epoch  34 Batch  400/2536 - Train Accuracy: 0.7480, Validation Accuracy: 0.6339, Loss: 0.9598\n",
      "Epoch  34 Batch  500/2536 - Train Accuracy: 0.7042, Validation Accuracy: 0.6339, Loss: 1.2142\n",
      "Epoch  34 Batch  600/2536 - Train Accuracy: 0.6833, Validation Accuracy: 0.6339, Loss: 1.1668\n",
      "Epoch  34 Batch  700/2536 - Train Accuracy: 0.7067, Validation Accuracy: 0.6339, Loss: 1.2049\n",
      "Epoch  34 Batch  800/2536 - Train Accuracy: 0.6875, Validation Accuracy: 0.6339, Loss: 1.3025\n",
      "Epoch  34 Batch  900/2536 - Train Accuracy: 0.6406, Validation Accuracy: 0.6339, Loss: 1.3467\n",
      "Epoch  34 Batch 1000/2536 - Train Accuracy: 0.6729, Validation Accuracy: 0.6339, Loss: 1.3031\n",
      "Epoch  34 Batch 1100/2536 - Train Accuracy: 0.5558, Validation Accuracy: 0.6339, Loss: 1.7775\n",
      "Epoch  34 Batch 1200/2536 - Train Accuracy: 0.6660, Validation Accuracy: 0.6339, Loss: 1.2239\n",
      "Epoch  34 Batch 1300/2536 - Train Accuracy: 0.9327, Validation Accuracy: 0.6339, Loss: 0.2810\n",
      "Epoch  34 Batch 1400/2536 - Train Accuracy: 0.6312, Validation Accuracy: 0.6339, Loss: 1.4300\n",
      "Epoch  34 Batch 1500/2536 - Train Accuracy: 0.8029, Validation Accuracy: 0.6339, Loss: 0.7882\n",
      "Epoch  34 Batch 1600/2536 - Train Accuracy: 0.7708, Validation Accuracy: 0.6339, Loss: 1.0027\n",
      "Epoch  34 Batch 1700/2536 - Train Accuracy: 0.8040, Validation Accuracy: 0.6339, Loss: 0.7721\n",
      "Epoch  34 Batch 1800/2536 - Train Accuracy: 0.8608, Validation Accuracy: 0.6339, Loss: 0.5371\n",
      "Epoch  34 Batch 1900/2536 - Train Accuracy: 0.7474, Validation Accuracy: 0.6339, Loss: 0.9018\n",
      "Epoch  34 Batch 2000/2536 - Train Accuracy: 0.7572, Validation Accuracy: 0.6339, Loss: 0.9598\n",
      "Epoch  34 Batch 2100/2536 - Train Accuracy: 0.9010, Validation Accuracy: 0.6339, Loss: 0.3297\n",
      "Epoch  34 Batch 2200/2536 - Train Accuracy: 0.7521, Validation Accuracy: 0.6339, Loss: 1.0091\n",
      "Epoch  34 Batch 2300/2536 - Train Accuracy: 0.5649, Validation Accuracy: 0.6339, Loss: 1.8338\n",
      "Epoch  34 Batch 2400/2536 - Train Accuracy: 0.6923, Validation Accuracy: 0.6339, Loss: 1.2997\n",
      "Epoch  34 Batch 2500/2536 - Train Accuracy: 0.5697, Validation Accuracy: 0.6339, Loss: 1.6911\n",
      "Epoch  35 Batch  100/2536 - Train Accuracy: 0.8210, Validation Accuracy: 0.6339, Loss: 0.6605\n",
      "Epoch  35 Batch  200/2536 - Train Accuracy: 0.8036, Validation Accuracy: 0.6339, Loss: 0.7668\n",
      "Epoch  35 Batch  300/2536 - Train Accuracy: 0.8170, Validation Accuracy: 0.6339, Loss: 0.6335\n",
      "Epoch  35 Batch  400/2536 - Train Accuracy: 0.7598, Validation Accuracy: 0.6339, Loss: 0.9187\n",
      "Epoch  35 Batch  500/2536 - Train Accuracy: 0.7042, Validation Accuracy: 0.6339, Loss: 1.1827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  35 Batch  600/2536 - Train Accuracy: 0.6771, Validation Accuracy: 0.6339, Loss: 1.1155\n",
      "Epoch  35 Batch  700/2536 - Train Accuracy: 0.7380, Validation Accuracy: 0.6339, Loss: 1.1605\n",
      "Epoch  35 Batch  800/2536 - Train Accuracy: 0.7091, Validation Accuracy: 0.6339, Loss: 1.2464\n",
      "Epoch  35 Batch  900/2536 - Train Accuracy: 0.6473, Validation Accuracy: 0.6339, Loss: 1.3441\n",
      "Epoch  35 Batch 1000/2536 - Train Accuracy: 0.6562, Validation Accuracy: 0.6339, Loss: 1.2604\n",
      "Epoch  35 Batch 1100/2536 - Train Accuracy: 0.5335, Validation Accuracy: 0.6339, Loss: 1.7443\n",
      "Epoch  35 Batch 1200/2536 - Train Accuracy: 0.6602, Validation Accuracy: 0.6339, Loss: 1.1623\n",
      "Epoch  35 Batch 1300/2536 - Train Accuracy: 0.9159, Validation Accuracy: 0.6339, Loss: 0.2598\n",
      "Epoch  35 Batch 1400/2536 - Train Accuracy: 0.6312, Validation Accuracy: 0.6339, Loss: 1.3730\n",
      "Epoch  35 Batch 1500/2536 - Train Accuracy: 0.8101, Validation Accuracy: 0.6339, Loss: 0.7698\n",
      "Epoch  35 Batch 1600/2536 - Train Accuracy: 0.7526, Validation Accuracy: 0.6339, Loss: 0.9649\n",
      "Epoch  35 Batch 1700/2536 - Train Accuracy: 0.8239, Validation Accuracy: 0.6339, Loss: 0.7504\n",
      "Epoch  35 Batch 1800/2536 - Train Accuracy: 0.8750, Validation Accuracy: 0.6339, Loss: 0.5287\n",
      "Epoch  35 Batch 1900/2536 - Train Accuracy: 0.7865, Validation Accuracy: 0.6339, Loss: 0.8711\n",
      "Epoch  35 Batch 2000/2536 - Train Accuracy: 0.7404, Validation Accuracy: 0.6339, Loss: 0.9204\n",
      "Epoch  35 Batch 2100/2536 - Train Accuracy: 0.9036, Validation Accuracy: 0.6339, Loss: 0.2810\n",
      "Epoch  35 Batch 2200/2536 - Train Accuracy: 0.7792, Validation Accuracy: 0.6339, Loss: 1.0032\n",
      "Epoch  35 Batch 2300/2536 - Train Accuracy: 0.5601, Validation Accuracy: 0.6339, Loss: 1.7628\n",
      "Epoch  35 Batch 2400/2536 - Train Accuracy: 0.6995, Validation Accuracy: 0.6339, Loss: 1.2331\n",
      "Epoch  35 Batch 2500/2536 - Train Accuracy: 0.6130, Validation Accuracy: 0.6339, Loss: 1.6660\n",
      "Epoch  36 Batch  100/2536 - Train Accuracy: 0.8523, Validation Accuracy: 0.6339, Loss: 0.6330\n",
      "Epoch  36 Batch  200/2536 - Train Accuracy: 0.8147, Validation Accuracy: 0.6339, Loss: 0.7564\n",
      "Epoch  36 Batch  300/2536 - Train Accuracy: 0.8326, Validation Accuracy: 0.6362, Loss: 0.6180\n",
      "Epoch  36 Batch  400/2536 - Train Accuracy: 0.7383, Validation Accuracy: 0.6339, Loss: 0.9087\n",
      "Epoch  36 Batch  500/2536 - Train Accuracy: 0.7167, Validation Accuracy: 0.6362, Loss: 1.1597\n",
      "Epoch  36 Batch  600/2536 - Train Accuracy: 0.7125, Validation Accuracy: 0.6339, Loss: 1.0864\n",
      "Epoch  36 Batch  700/2536 - Train Accuracy: 0.7067, Validation Accuracy: 0.6339, Loss: 1.1271\n",
      "Epoch  36 Batch  800/2536 - Train Accuracy: 0.6851, Validation Accuracy: 0.6362, Loss: 1.2063\n",
      "Epoch  36 Batch  900/2536 - Train Accuracy: 0.6540, Validation Accuracy: 0.6339, Loss: 1.2814\n",
      "Epoch  36 Batch 1000/2536 - Train Accuracy: 0.6625, Validation Accuracy: 0.6339, Loss: 1.2400\n",
      "Epoch  36 Batch 1100/2536 - Train Accuracy: 0.5446, Validation Accuracy: 0.6339, Loss: 1.7086\n",
      "Epoch  36 Batch 1200/2536 - Train Accuracy: 0.6602, Validation Accuracy: 0.6339, Loss: 1.1258\n",
      "Epoch  36 Batch 1300/2536 - Train Accuracy: 0.9447, Validation Accuracy: 0.6339, Loss: 0.2389\n",
      "Epoch  36 Batch 1400/2536 - Train Accuracy: 0.6833, Validation Accuracy: 0.6339, Loss: 1.3542\n",
      "Epoch  36 Batch 1500/2536 - Train Accuracy: 0.8101, Validation Accuracy: 0.6339, Loss: 0.7226\n",
      "Epoch  36 Batch 1600/2536 - Train Accuracy: 0.7865, Validation Accuracy: 0.6339, Loss: 0.9213\n",
      "Epoch  36 Batch 1700/2536 - Train Accuracy: 0.8068, Validation Accuracy: 0.6339, Loss: 0.7141\n",
      "Epoch  36 Batch 1800/2536 - Train Accuracy: 0.8778, Validation Accuracy: 0.6339, Loss: 0.4981\n",
      "Epoch  36 Batch 1900/2536 - Train Accuracy: 0.7839, Validation Accuracy: 0.6339, Loss: 0.8284\n",
      "Epoch  38 Batch  600/2536 - Train Accuracy: 0.7375, Validation Accuracy: 0.6362, Loss: 1.0684\n",
      "Epoch  38 Batch  700/2536 - Train Accuracy: 0.7500, Validation Accuracy: 0.6362, Loss: 1.0550\n",
      "Epoch  38 Batch  800/2536 - Train Accuracy: 0.6947, Validation Accuracy: 0.6362, Loss: 1.1499\n",
      "Epoch  38 Batch  900/2536 - Train Accuracy: 0.6696, Validation Accuracy: 0.6362, Loss: 1.2271\n",
      "Epoch  38 Batch 1000/2536 - Train Accuracy: 0.6750, Validation Accuracy: 0.6362, Loss: 1.1772\n",
      "Epoch  38 Batch 1100/2536 - Train Accuracy: 0.5781, Validation Accuracy: 0.6339, Loss: 1.6081\n",
      "Epoch  38 Batch 1200/2536 - Train Accuracy: 0.6738, Validation Accuracy: 0.6339, Loss: 1.0663\n",
      "Epoch  38 Batch 1300/2536 - Train Accuracy: 0.9567, Validation Accuracy: 0.6339, Loss: 0.2049\n",
      "Epoch  38 Batch 1400/2536 - Train Accuracy: 0.6729, Validation Accuracy: 0.6339, Loss: 1.2676\n",
      "Epoch  38 Batch 1500/2536 - Train Accuracy: 0.8293, Validation Accuracy: 0.6339, Loss: 0.6676\n",
      "Epoch  38 Batch 1600/2536 - Train Accuracy: 0.7865, Validation Accuracy: 0.6362, Loss: 0.8621\n",
      "Epoch  38 Batch 1700/2536 - Train Accuracy: 0.8494, Validation Accuracy: 0.6339, Loss: 0.6819\n",
      "Epoch  38 Batch 1800/2536 - Train Accuracy: 0.9034, Validation Accuracy: 0.6362, Loss: 0.4655\n",
      "Epoch  38 Batch 1900/2536 - Train Accuracy: 0.7943, Validation Accuracy: 0.6339, Loss: 0.7799\n",
      "Epoch  38 Batch 2000/2536 - Train Accuracy: 0.7548, Validation Accuracy: 0.6339, Loss: 0.8146\n",
      "Epoch  38 Batch 2100/2536 - Train Accuracy: 0.9583, Validation Accuracy: 0.6339, Loss: 0.2404\n",
      "Epoch  38 Batch 2200/2536 - Train Accuracy: 0.7583, Validation Accuracy: 0.6339, Loss: 0.8988\n",
      "Epoch  38 Batch 2300/2536 - Train Accuracy: 0.5938, Validation Accuracy: 0.6339, Loss: 1.6608\n",
      "Epoch  38 Batch 2400/2536 - Train Accuracy: 0.7043, Validation Accuracy: 0.6339, Loss: 1.1482\n",
      "Epoch  38 Batch 2500/2536 - Train Accuracy: 0.6202, Validation Accuracy: 0.6339, Loss: 1.5659\n",
      "Epoch  39 Batch  100/2536 - Train Accuracy: 0.8807, Validation Accuracy: 0.6339, Loss: 0.5373\n",
      "Epoch  39 Batch  200/2536 - Train Accuracy: 0.8281, Validation Accuracy: 0.6362, Loss: 0.6878\n",
      "Epoch  39 Batch  300/2536 - Train Accuracy: 0.8438, Validation Accuracy: 0.6362, Loss: 0.5602\n",
      "Epoch  39 Batch  400/2536 - Train Accuracy: 0.7734, Validation Accuracy: 0.6362, Loss: 0.8430\n",
      "Epoch  39 Batch  500/2536 - Train Accuracy: 0.7417, Validation Accuracy: 0.6362, Loss: 1.1031\n",
      "Epoch  39 Batch  600/2536 - Train Accuracy: 0.7312, Validation Accuracy: 0.6362, Loss: 1.0052\n",
      "Epoch  39 Batch  700/2536 - Train Accuracy: 0.7428, Validation Accuracy: 0.6362, Loss: 1.0246\n",
      "Epoch  39 Batch  800/2536 - Train Accuracy: 0.7212, Validation Accuracy: 0.6362, Loss: 1.1055\n",
      "Epoch  39 Batch  900/2536 - Train Accuracy: 0.6518, Validation Accuracy: 0.6362, Loss: 1.1811\n",
      "Epoch  39 Batch 1000/2536 - Train Accuracy: 0.6583, Validation Accuracy: 0.6362, Loss: 1.1546\n",
      "Epoch  39 Batch 1100/2536 - Train Accuracy: 0.5692, Validation Accuracy: 0.6362, Loss: 1.6101\n",
      "Epoch  39 Batch 1200/2536 - Train Accuracy: 0.6660, Validation Accuracy: 0.6339, Loss: 1.0722\n",
      "Epoch  39 Batch 1300/2536 - Train Accuracy: 0.9567, Validation Accuracy: 0.6339, Loss: 0.1930\n",
      "Epoch  39 Batch 1400/2536 - Train Accuracy: 0.6562, Validation Accuracy: 0.6362, Loss: 1.2290\n",
      "Epoch  39 Batch 1500/2536 - Train Accuracy: 0.8534, Validation Accuracy: 0.6339, Loss: 0.6501\n",
      "Epoch  39 Batch 1600/2536 - Train Accuracy: 0.7969, Validation Accuracy: 0.6339, Loss: 0.8254\n",
      "Epoch  39 Batch 1700/2536 - Train Accuracy: 0.8409, Validation Accuracy: 0.6339, Loss: 0.6638\n",
      "Epoch  39 Batch 1800/2536 - Train Accuracy: 0.9034, Validation Accuracy: 0.6339, Loss: 0.4488\n",
      "Epoch  39 Batch 1900/2536 - Train Accuracy: 0.8125, Validation Accuracy: 0.6339, Loss: 0.7657\n",
      "Epoch  39 Batch 2000/2536 - Train Accuracy: 0.7740, Validation Accuracy: 0.6339, Loss: 0.8011\n",
      "Epoch  39 Batch 2100/2536 - Train Accuracy: 0.9557, Validation Accuracy: 0.6339, Loss: 0.2259\n",
      "Epoch  39 Batch 2200/2536 - Train Accuracy: 0.7646, Validation Accuracy: 0.6339, Loss: 0.8818\n",
      "Epoch  39 Batch 2300/2536 - Train Accuracy: 0.5817, Validation Accuracy: 0.6339, Loss: 1.5877\n",
      "Epoch  39 Batch 2400/2536 - Train Accuracy: 0.7260, Validation Accuracy: 0.6339, Loss: 1.1021\n",
      "Epoch  39 Batch 2500/2536 - Train Accuracy: 0.6202, Validation Accuracy: 0.6339, Loss: 1.5001\n",
      "Epoch  40 Batch  100/2536 - Train Accuracy: 0.8693, Validation Accuracy: 0.6339, Loss: 0.5230\n",
      "Epoch  40 Batch  200/2536 - Train Accuracy: 0.8415, Validation Accuracy: 0.6362, Loss: 0.6612\n",
      "Epoch  40 Batch  300/2536 - Train Accuracy: 0.8504, Validation Accuracy: 0.6362, Loss: 0.5309\n",
      "Epoch  40 Batch  400/2536 - Train Accuracy: 0.8027, Validation Accuracy: 0.6362, Loss: 0.8255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  40 Batch  500/2536 - Train Accuracy: 0.7063, Validation Accuracy: 0.6362, Loss: 1.0474\n",
      "Epoch  40 Batch  600/2536 - Train Accuracy: 0.7312, Validation Accuracy: 0.6362, Loss: 0.9738\n",
      "Epoch  40 Batch  700/2536 - Train Accuracy: 0.7404, Validation Accuracy: 0.6362, Loss: 0.9923\n",
      "Epoch  40 Batch  800/2536 - Train Accuracy: 0.7139, Validation Accuracy: 0.6362, Loss: 1.0878\n",
      "Epoch  40 Batch  900/2536 - Train Accuracy: 0.6763, Validation Accuracy: 0.6362, Loss: 1.1523\n",
      "Epoch  40 Batch 1000/2536 - Train Accuracy: 0.6833, Validation Accuracy: 0.6362, Loss: 1.1047\n",
      "Epoch  40 Batch 1100/2536 - Train Accuracy: 0.5915, Validation Accuracy: 0.6339, Loss: 1.5424\n",
      "Epoch  40 Batch 1200/2536 - Train Accuracy: 0.6953, Validation Accuracy: 0.6339, Loss: 1.0213\n",
      "Epoch  40 Batch 1300/2536 - Train Accuracy: 0.9567, Validation Accuracy: 0.6339, Loss: 0.1738\n",
      "Epoch  40 Batch 1400/2536 - Train Accuracy: 0.6604, Validation Accuracy: 0.6339, Loss: 1.1958\n",
      "Epoch  40 Batch 1500/2536 - Train Accuracy: 0.8317, Validation Accuracy: 0.6339, Loss: 0.6120\n",
      "Epoch  40 Batch 1600/2536 - Train Accuracy: 0.7891, Validation Accuracy: 0.6339, Loss: 0.7932\n",
      "Epoch  40 Batch 1700/2536 - Train Accuracy: 0.8580, Validation Accuracy: 0.6339, Loss: 0.6234\n",
      "Epoch  40 Batch 1800/2536 - Train Accuracy: 0.8949, Validation Accuracy: 0.6339, Loss: 0.4162\n",
      "Epoch  40 Batch 1900/2536 - Train Accuracy: 0.8203, Validation Accuracy: 0.6339, Loss: 0.7460\n",
      "Epoch  40 Batch 2000/2536 - Train Accuracy: 0.7716, Validation Accuracy: 0.6339, Loss: 0.7520\n",
      "Epoch  40 Batch 2100/2536 - Train Accuracy: 0.9740, Validation Accuracy: 0.6339, Loss: 0.2030\n",
      "Epoch  40 Batch 2200/2536 - Train Accuracy: 0.7708, Validation Accuracy: 0.6339, Loss: 0.8519\n",
      "Epoch  40 Batch 2300/2536 - Train Accuracy: 0.6154, Validation Accuracy: 0.6362, Loss: 1.5482\n",
      "Epoch  40 Batch 2400/2536 - Train Accuracy: 0.7260, Validation Accuracy: 0.6362, Loss: 1.0738\n",
      "Epoch  40 Batch 2500/2536 - Train Accuracy: 0.6034, Validation Accuracy: 0.6339, Loss: 1.4265\n",
      "Epoch  41 Batch  100/2536 - Train Accuracy: 0.8722, Validation Accuracy: 0.6339, Loss: 0.4931\n",
      "Epoch  41 Batch  200/2536 - Train Accuracy: 0.8348, Validation Accuracy: 0.6362, Loss: 0.6501\n",
      "Epoch  41 Batch  300/2536 - Train Accuracy: 0.8438, Validation Accuracy: 0.6362, Loss: 0.5283\n",
      "Epoch  41 Batch  400/2536 - Train Accuracy: 0.7832, Validation Accuracy: 0.6362, Loss: 0.7888\n",
      "Epoch  41 Batch  500/2536 - Train Accuracy: 0.7417, Validation Accuracy: 0.6362, Loss: 1.0573\n",
      "Epoch  41 Batch  600/2536 - Train Accuracy: 0.7500, Validation Accuracy: 0.6362, Loss: 0.9403\n",
      "Epoch  41 Batch  700/2536 - Train Accuracy: 0.7067, Validation Accuracy: 0.6362, Loss: 0.9586\n",
      "Epoch  41 Batch  800/2536 - Train Accuracy: 0.6947, Validation Accuracy: 0.6362, Loss: 1.0598\n",
      "Epoch  41 Batch  900/2536 - Train Accuracy: 0.6562, Validation Accuracy: 0.6362, Loss: 1.1176\n",
      "Epoch  41 Batch 1000/2536 - Train Accuracy: 0.6937, Validation Accuracy: 0.6362, Loss: 1.0935\n",
      "Epoch  41 Batch 1100/2536 - Train Accuracy: 0.5603, Validation Accuracy: 0.6362, Loss: 1.5376\n",
      "Epoch  41 Batch 1200/2536 - Train Accuracy: 0.6641, Validation Accuracy: 0.6362, Loss: 0.9837\n",
      "Epoch  41 Batch 1300/2536 - Train Accuracy: 0.9663, Validation Accuracy: 0.6362, Loss: 0.1675\n",
      "Epoch  41 Batch 1400/2536 - Train Accuracy: 0.6896, Validation Accuracy: 0.6339, Loss: 1.1763\n",
      "Epoch  41 Batch 1500/2536 - Train Accuracy: 0.8438, Validation Accuracy: 0.6339, Loss: 0.5992\n",
      "Epoch  41 Batch 1600/2536 - Train Accuracy: 0.7891, Validation Accuracy: 0.6339, Loss: 0.7739\n",
      "Epoch  41 Batch 1700/2536 - Train Accuracy: 0.8494, Validation Accuracy: 0.6339, Loss: 0.6105\n",
      "Epoch  41 Batch 1800/2536 - Train Accuracy: 0.8977, Validation Accuracy: 0.6339, Loss: 0.4058\n",
      "Epoch  41 Batch 1900/2536 - Train Accuracy: 0.8021, Validation Accuracy: 0.6362, Loss: 0.7060\n",
      "Epoch  41 Batch 2000/2536 - Train Accuracy: 0.8029, Validation Accuracy: 0.6339, Loss: 0.7158\n"
     ]
    }
   ],
   "source": [
    "for speaker_id, lexicon in lexicons.items():\n",
    "    lexicon.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameters for checkpoint\n",
    "helper.save_params(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper\n",
    "\n",
    "_, (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab, target_int_to_vocab) = helper.load_preprocess()\n",
    "load_path = helper.load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_seq(sentence, vocab_to_int):\n",
    "    \"\"\"\n",
    "    Convert a sentence to a sequence of ids\n",
    "    :param sentence: String\n",
    "    :param vocab_to_int: Dictionary to go from the words to an id\n",
    "    :return: List of word ids\n",
    "    \"\"\"\n",
    "        \n",
    "    # Convert the sentence to lowercase and to list\n",
    "    list_words = [word for word in sentence.lower().split() ]\n",
    "    \n",
    "    # Convert words into ids using vocab_to_int\n",
    "    list_words_int = list()\n",
    "    for word in list_words:\n",
    "        # Convert words not in the vocabulary, to the <UNK> word id.\n",
    "        if word not in vocab_to_int:\n",
    "            list_words_int.append(vocab_to_int['<UNK>'])\n",
    "        else:\n",
    "            list_words_int.append(vocab_to_int[word])\n",
    "    return list_words_int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import operator\n",
    "\n",
    "token_dict = token_lookup()\n",
    "steps = 0\n",
    "show_results = 1000\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    for speaker_id, lexicon in lexicons.items():\n",
    "        # Load saved model\n",
    "        checkpoint_dir = os.path.join(lexicon.cache_dir,'checkpoints')\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, 'model.ckpt'\n",
    "        loader = tf.train.import_meta_graph(checkpoint_dir + '.meta')\n",
    "        loader.restore(sess, checkpoint_path)\n",
    "\n",
    "        input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "        logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "        target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n",
    "        source_sequence_length = loaded_graph.get_tensor_by_name('source_sequence_length:0')\n",
    "        keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    \n",
    "        for speech in lexicon.speeches:\n",
    "            gt_transcript = speech.ground_truth_transcript.lower()\n",
    "            for key, token in token_dict.items():\n",
    "                gt_transcript = gt_transcript.replace(key, ' {} '.format(token))\n",
    "\n",
    "            cloud_speech_api_accuracy = []\n",
    "            custom_lang_model_accuracy = []\n",
    "\n",
    "\n",
    "            # Collect Google API Transcript\n",
    "            google_api_transcript = \"\"\n",
    "            words = []\n",
    "            if speech.candidate_timestamps:\n",
    "                for candidate_timestamp in speech.candidate_timestamps:\n",
    "                    words.append(candidate_timestamp[\"word\"])\n",
    "                google_api_transcript = \" \".join(words)\n",
    "\n",
    "\n",
    "            if speech.candidate_timestamps:\n",
    "                candidate_script_accuracy = []\n",
    "                for candidate_transcript in speech.candidate_transcripts:\n",
    "                    steps +=1\n",
    "                    transcription_sentence = sentence_to_seq(candidate_transcript[\"transcript\"], source_vocab_to_int)\n",
    "\n",
    "                    transcription_logits = sess.run(logits, {input_data: [transcription_sentence]*batch_size,\n",
    "                                                         target_sequence_length: [len(transcription_sentence)*2]*batch_size,\n",
    "                                                         source_sequence_length: [len(transcription_sentence)]*batch_size,\n",
    "                                                         keep_prob: 1.0})[0]\n",
    "                    prediction_transcript = \" \".join([target_int_to_vocab[i] for i in transcription_logits])\n",
    "                    # Remove <EOS> Token\n",
    "                    prediction_transcript = prediction_transcript.replace('<EOS>','')\n",
    "\n",
    "                    if steps % show_results == 0:  \n",
    "                        print()\n",
    "                        print('GCS Candidate Transcript: \\n{}'.format(\" \".join([source_int_to_vocab[i] for i in transcription_sentence])))\n",
    "                        print('Seq2Seq Model Prediction Transcript: \\n{}'.format(prediction_transcript))\n",
    "                        print('Ground Truth Transcript: \\n{}'.format(gt_transcript))\n",
    "                        print()\n",
    "\n",
    "                    # Compute the Candidate Transcript Edit Distance (a.k.a. From the Predicted Distance)\n",
    "                    # Use this to determine how likely sentence would have been predicted\n",
    "                    gct_ed = nltk.edit_distance(candidate_transcript[\"transcript\"].lower(), prediction_transcript.lower())\n",
    "                    gct_upper_bound = max(len(candidate_transcript[\"transcript\"]),len(prediction_transcript))\n",
    "                    gct_accuracy = (1.0 - gct_ed/gct_upper_bound)\n",
    "\n",
    "                    gct_accuracy = gct_accuracy*candidate_transcript[\"confidence\"]\n",
    "                    candidate_script_accuracy.append(gct_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "                # Select Candidate Transcript with the highest accuracy (to prediction)\n",
    "\n",
    "                index, value = max(enumerate(candidate_script_accuracy), key=operator.itemgetter(1))\n",
    "\n",
    "                tmp = []\n",
    "                for candidate_transcript in speech.candidate_transcripts:\n",
    "                    tmp.append(candidate_transcript[\"transcript\"])\n",
    "\n",
    "                reranked_transcript = tmp[index]\n",
    "\n",
    "\n",
    "                # Collect Accuracy between reranked transcript and Google transcript                      \n",
    "                gcs_ed = nltk.edit_distance(google_api_transcript.lower(), gt_transcript.lower())\n",
    "                gcs_upper_bound = max(len(google_api_transcript),len(gt_transcript))\n",
    "                gcs_accuracy = (1.0 - gcs_ed/gcs_upper_bound)\n",
    "\n",
    "                clm_ed = nltk.edit_distance(reranked_transcript.lower(), gt_transcript.lower())\n",
    "                clm_upper_bound = max(len(reranked_transcript),len(gt_transcript))\n",
    "                clm_accuracy = (1.0 - clm_ed/clm_upper_bound)\n",
    "\n",
    "                cloud_speech_api_accuracy.append(gcs_accuracy)\n",
    "                custom_lang_model_accuracy.append(clm_accuracy)\n",
    "\n",
    "    print('Speech Results:')\n",
    "    print('Average Candidate Transcript Accuracy:', np.mean(cloud_speech_api_accuracy))\n",
    "    print('Average Seq2Seq Model Accuracy:', np.mean(custom_lang_model_accuracy))\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
